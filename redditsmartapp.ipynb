{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b089b3",
   "metadata": {},
   "source": [
    "# Examination of Digital Community Conversations Within Specific Disease States Via Reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e37553",
   "metadata": {},
   "source": [
    "- **Vision**: Development of a repeatable process for the analysis of Reddit conversations\n",
    "within specific condition and/or disease state with applicable threads and subreddit\n",
    "threads (subreddits) to potentially inform strategy and content development. Create a\n",
    "simplified and repeatable process that does not require the users to be fluent in Reddit.\n",
    "- **Issue**: While Reddit offers robust, open, and community-minded discussions surrounding\n",
    "conditions and disease states, Reddit also provides volumes of unstructured and\n",
    "unclassified data. The development of a repeatable process ‚Äì that continues to monitor\n",
    "evolving conversations over time ‚Äì currently requires multiple tools (ex. ‚Äì tools to scrape\n",
    "threads, tools to analyze keyword content, tools to analyze sentiment, etc.).\n",
    "- **Method**: After identifying priority conditions and/or disease states with active Reddit\n",
    "communities (ex. ‚Äì prostate cancer, breast cancer, HIV, etc.), build relational taxonomy\n",
    "(ex. ‚Äì medicine, treatment, and adherence all have specific topics but have relational\n",
    "discussions) of topical themes addressed within.\n",
    "- **Potential Output**: Provide use case for healthcare companies on the importance of\n",
    "Reddit as an early source of social indicator of trends and conversational ‚Äúlexicon‚Äù to be\n",
    "used for patient communications and programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ae8ae0",
   "metadata": {},
   "source": [
    "Contents\n",
    "\n",
    "1. Introduction\n",
    "2. Types of Text Summarization\n",
    "3. Text Summarization using Gensim\n",
    "4. Text Summarization with sumy\n",
    "* LexRank\n",
    "* LSA (Latent Semantic Analysis )\n",
    "* Luhn\n",
    "* KL-Sum\n",
    "5. What is Abstractive Text Summarization\n",
    "5. T5 Transformers for Text Summarization\n",
    "6. BART Transformers for Text Summarization\n",
    "7. GPT-2 Transformers for Text Summarization\n",
    "8. XLM Transformers for Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee48c5f",
   "metadata": {},
   "source": [
    "# <font color='Green'><center>Milestone 4: Web App</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89b4a6",
   "metadata": {},
   "source": [
    "# <font color='Red'><center>I- Summarization</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81ed044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='img/logo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f581ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rmastour\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "# Streamlit App: Core Packages\n",
    "import streamlit as st\n",
    "import os\n",
    "\n",
    "#Sentiment Analysis: NLP Packages\n",
    "from textblob import TextBlob\n",
    "from gensim.summarization.summarizer import summarize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "#NER Imports\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Sumy Summary Pkg\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "\n",
    "from gensim.summarization.summarizer import summarize \n",
    "from gensim.summarization import keywords\n",
    "\n",
    "#Visualization\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1521db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from dataset_milestone1 import df\n",
    "from cancer_dataset import cancer as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf50a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usefulText(dataframe, L):\n",
    "    #Assemble the text in list\n",
    "    text = []\n",
    "    for i in range(L):\n",
    "        hnaya = dataframe['comments'][i].body[0]\n",
    "        text.append(hnaya)\n",
    "    \n",
    "    #Merge it all in paragraphe to be summarized or sentiment analyzed\n",
    "    prompt = ''    \n",
    "    for i in text:\n",
    "        prompt = prompt + i\n",
    "        \n",
    "    #before returning text, let's check the limits\n",
    "    info = (prompt[:2048] + '..') if len(prompt) > 2048 else prompt\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "872d2ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 10:54:56.694 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\rmastour\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "#Headings for Web Application\n",
    "st.title(\"Natural Language Processing Web Application Example\")\n",
    "st.subheader(\"What type of NLP service would you like to use?\")\n",
    "\n",
    "#Picking what NLP task you want to do\n",
    "option = st.selectbox('NLP Service',('Sentiment Analysis', 'Entity Extraction', 'Text Summarization')) #option is stored in this variable\n",
    "\n",
    "#Textbox for text user is entering\n",
    "st.subheader(\"Enter the text you'd like to analyze.\")\n",
    "text = st.text_input('Enter text') #text is stored in this variable\n",
    "\n",
    "#Display results of the NLP task\n",
    "st.header(\"Results\")\n",
    "\n",
    "#Function to take in dictionary of entities, type of entity, and returns specific entities of specific type\n",
    "def entRecognizer(entDict, typeEnt):\n",
    "    entList = [ent for ent in entDict if entDict[ent] == typeEnt]\n",
    "    return entList\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57953eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmastour\\Anaconda3\\lib\\site-packages\\altair\\utils\\core.py:185: UserWarning: I don't know how to infer vegalite type from 'empty'.  Defaulting to nominal.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Sentiment Analysis\n",
    "if option == 'Sentiment Analysis':\n",
    "    \n",
    "    #Creating graph for sentiment across each sentence in the text inputted\n",
    "    sents = sent_tokenize(text) #tokenizing the text data into a list of sentences\n",
    "    entireText = TextBlob(text) #storing the entire text in one string\n",
    "    sentScores = [] #storing sentences in a list to plot\n",
    "    for sent in sents:\n",
    "        text = TextBlob(sent) #sentiment for each sentence\n",
    "        score = text.sentiment[0] #extracting polarity of each sentence\n",
    "        sentScores.append(score) \n",
    "\n",
    "    #Plotting sentiment scores per sentencein line graph\n",
    "    st.line_chart(sentScores) #using line_chart st call to plot polarity for each sentence\n",
    "    \n",
    "\n",
    "    #Polarity and Subjectivity of the entire text inputted\n",
    "    sentimentTotal = entireText.sentiment\n",
    "    st.write(\"The sentiment of the overall text below.\")\n",
    "    st.write(sentimentTotal)\n",
    "    \n",
    "    \n",
    "\n",
    "#Named Entity Recognition\n",
    "elif option == 'Entity Extraction':\n",
    "\n",
    "    #Getting Entity and type of Entity\n",
    "    entities = [] #list for all entities\n",
    "    entityLabels = [] #list for type of entities\n",
    "    doc = nlp(text) #this call extracts all entities, make sure the spacy en library is loaded\n",
    "    #iterate through all entities\n",
    "    for ent in doc.ents:\n",
    "        entities.append(ent.text)\n",
    "        entityLabels.append(ent.label_)\n",
    "    entDict = dict(zip(entities, entityLabels)) #Creating dictionary with entity and entity types\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Using function to create lists of entities of each type\n",
    "    entOrg = entRecognizer(entDict, \"ORG\")\n",
    "    entCardinal = entRecognizer(entDict, \"CARDINAL\")\n",
    "    entPerson = entRecognizer(entDict, \"PERSON\")\n",
    "    entDate = entRecognizer(entDict, \"DATE\")\n",
    "    entGPE = entRecognizer(entDict, \"GPE\")\n",
    "\n",
    "    #Displaying entities of each type\n",
    "    st.write(\"Organization Entities: \" + str(entOrg))\n",
    "    st.write(\"Cardinal Entities: \" + str(entCardinal))\n",
    "    st.write(\"Personal Entities: \" + str(entPerson))\n",
    "    st.write(\"Date Entities: \" + str(entDate))\n",
    "    st.write(\"GPE Entities: \" + str(entGPE))\n",
    "\n",
    "#Text Summarization\n",
    "else:\n",
    "    summWords = summarize(text)\n",
    "    st.subheader(\"Summary\")\n",
    "    st.write(summWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b4642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac462ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = usefulText(df, 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97ecd8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT-3 Text summarizer\n",
    "def gptSummarizer(text):\n",
    "    import os\n",
    "    import openai\n",
    "\n",
    "    openai.api_key = \"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\"\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "      engine=\"davinci-instruct-beta\",\n",
    "      prompt=text,\n",
    "      temperature=1,\n",
    "      max_tokens=100,\n",
    "      top_p=1.0,\n",
    "      frequency_penalty=0.0,\n",
    "      presence_penalty=0.0\n",
    "    )\n",
    "    A = response.get('choices')[0]\n",
    "    answer = A.get('text')\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4be67e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT-3 Sentiment Analysis\n",
    "def gptsentiment(text):\n",
    "    import os\n",
    "    import openai\n",
    "    sentiment = openai.Completion.create(\n",
    "      engine=\"davinci\",\n",
    "      #prompt=\"This is a tweet sentiment classifier\\nTweet: \\\"I loved the new Batman movie!\\\"\\nSentiment: Positive\\n###\\nTweet: \\\"I hate it when my phone battery dies\\\"\\nSentiment: Negative\\n###\\nTweet: \\\"My day has been üëç\\\"\\nSentiment: Positive\\n###\\nTweet: \\\"This is the link to the article\\\"\\nSentiment: Neutral\\n###\\nTweet text\\n\\n\\n1. \\\"I loved the new Batman movie!\\\"\\n2. \\\"I hate it when my phone battery dies\\\"\\n3. \\\"My day has been üëç\\\"\\n4. \\\"This is the link to the article\\\"\\n5. \\\"This new music video blew my mind\\\"\\n\\n\\nTweet sentiment ratings:\\n1: Positive\\n2: Negative\\n3: Positive\\n4: Neutral\\n5: Positive\\n\\n\\n###\\nTweet text\\n\\n\\n1. \\\"I can't stand homework\\\"\\n2. \\\"This sucks. I'm bored üò†\\\"\\n3. \\\"I can't wait for Halloween!!!\\\"\\n4. \\\"My cat is adorable ‚ù§Ô∏è‚ù§Ô∏è\\\"\\n5. \\\"I hate chocolate\\\"\\n\\n\\nTweet sentiment ratings:\\n1.\",\n",
    "      prompt=text+\"###\",\n",
    "      temperature=0.3,\n",
    "      max_tokens=200,\n",
    "      top_p=1.0,\n",
    "      frequency_penalty=0.5,\n",
    "      presence_penalty=0.0,\n",
    "      stop=[\"###\"]\n",
    "    )\n",
    "    A = sentiment.get('choices')[0]\n",
    "    answer = A.get('text')\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "967e8c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 10:56:31.579 message='Request to OpenAI API' method=post path=https://api.openai.com/v1/engines/davinci-instruct-beta/completions\n",
      "2021-11-08 10:56:35.841 message='OpenAI API response' path=https://api.openai.com/v1/engines/davinci-instruct-beta/completions processing_ms=4178 response_code=200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"i mean a stroller. Tho we made memories. That‚Äôs much better than nothing. But I don‚Äôt remember it so much as much as I remember k to the n. I love and cherish the time we had, but darn if it ain't hard to do. It isn't bad at all I guess you might say. You don't know how good you had it. I guess its like this. Everything about her. Everyday. I know that I was happy\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gptSummarizer(mytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29a86c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 10:56:35.869 message='Request to OpenAI API' method=post path=https://api.openai.com/v1/engines/davinci/completions\n",
      "2021-11-08 10:56:43.814 message='OpenAI API response' path=https://api.openai.com/v1/engines/davinci/completions processing_ms=7159 response_code=200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'. I had to take her to the bathroom. I had to feed her, she was in a wheelchair. She was on oxygen. She couldn‚Äôt eat anything. She couldn‚Äôt drink anything. And she was so weak she couldn‚Äôt even hold her head up. And I remember looking at her and saying, ‚ÄúYou know what? We are going to have a great time!‚Äù And we did! We had the most wonderful time! We laughed and we cried and we held hands and we sang songs together. And when it was all over, she said, ‚ÄúMommy, that was the best day of my life!‚Äù So you can do this! You can do this! You can do this! You will have a wonderful time with your husband too! Just remember that he is your best friend and you love him more than anything in the whole wide world and you will have a great time together no matter where you go or what you'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gptsentiment(mytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f47af64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 10:56:50.894 message='Request to OpenAI API' method=post path=https://api.openai.com/v1/engines/davinci-instruct-beta/completions\n",
      "2021-11-08 10:56:55.658 message='OpenAI API response' path=https://api.openai.com/v1/engines/davinci-instruct-beta/completions processing_ms=4687 response_code=200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The top Indian institutions for this program is the Indian Institute of Technology Bombay (IIT‚Äôs), Indian Institute of Technology Kharagpur (IIT-KGP), Indian Institute of Technoloary Kanpur (IIT-K), Indian Institute of Technology Delhi (IIT-D), Jawaharlal Nehru Technological University, Hyderabad (JNTUH) and Ranchi‚Äôs Indian Institute of Technology Jharkhand (IIT JHAK). Five'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub which has been launched to empower the next generation of students with AI-ready skills. Envisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100 institutions with AI infrastructure, course content and curriculum, developer support, development tools and give students access to cloud and AI services. As part of the program, the Redmond giant which wants to expand its reach and is planning to build a strong developer ecosystem in India with the program will set up the core AI infrastructure and IoT Hub for the selected campuses. The company will provide AI development tools and Azure AI services such as Microsoft Cognitive Services, Bot Services and Azure Machine Learning.According to Manish Prakash, Country General Manager-PS, Health and Education, Microsoft India, said, \"With AI being the defining technology of our time, it is transforming lives and industry and the jobs of tomorrow will require a different skillset. This will require more collaborations and training and working with AI. That‚Äôs why it has become more critical than ever for educational institutions to integrate new cloud and AI technologies. The program is an attempt to ramp up the institutional set-up and build capabilities among the educators to educate the workforce of tomorrow.\" The program aims to build up the cognitive skills and in-depth understanding of developing intelligent cloud connected solutions for applications across industry. Earlier in April this year, the company announced Microsoft Professional Program In AI as a learning track open to the public. The program was developed to provide job ready skills to programmers who wanted to hone their skills in AI and data science with a series of online courses which featured hands-on labs and expert instructors as well. This program also included developer-focused AI school that provided a bunch of assets to help build AI skills.'\n",
    "gptSummarizer(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec9f8052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KLSummy(text):\n",
    "    # Creating the parser\n",
    "    from sumy.summarizers.kl import KLSummarizer\n",
    "    from sumy.nlp.tokenizers import Tokenizer\n",
    "    from sumy.parsers.plaintext import PlaintextParser\n",
    "    parser=PlaintextParser.from_string(text,Tokenizer('english'))\n",
    "    \n",
    "    # Instantiating the KLSummarizer\n",
    "    kl_summarizer=KLSummarizer()\n",
    "    kl_summary=kl_summarizer(parser.document,sentences_count=3)\n",
    "    \n",
    "    response = []\n",
    "    texto = ''\n",
    "    # Printing the summary\n",
    "    for sentence in kl_summary:\n",
    "        response.append(sentence)\n",
    "    \n",
    "    for i in response:\n",
    "        texto = texto + str(i)\n",
    "    \n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29344332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub which has been launched to empower the next generation of students with AI-ready skills.The program is an attempt to ramp up the institutional set-up and build capabilities among the educators to educate the workforce of tomorrow.\"The program aims to build up the cognitive skills and in-depth understanding of developing intelligent cloud connected solutions for applications across industry.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KLSummy(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75a12764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LexRank\n",
    "def LexRankSummarizer(text):\n",
    "    # Importing the parser and tokenizer\n",
    "    from sumy.parsers.plaintext import PlaintextParser\n",
    "    from sumy.nlp.tokenizers import Tokenizer\n",
    "    # Import the LexRank summarizer\n",
    "    from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "    \n",
    "    # Initializing the parser\n",
    "    my_parser = PlaintextParser.from_string(text,Tokenizer('english'))\n",
    "    \n",
    "    # Creating a summary of 3 sentences.\n",
    "    lex_rank_summarizer = LexRankSummarizer()\n",
    "    lexrank_summary = lex_rank_summarizer(my_parser.document,sentences_count=3)\n",
    "    \n",
    "    response = []\n",
    "    texto = ''\n",
    "    # Printing the summary\n",
    "    for sentence in lexrank_summary:\n",
    "        response.append(sentence)\n",
    "    \n",
    "    for i in response:\n",
    "        texto = texto + str(i)\n",
    "    \n",
    "    return texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fc5b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Luhn\n",
    "def LuhnSummy(text):\n",
    "    # Importing the parser and tokenizer\n",
    "    # Import the summarizer\n",
    "    from sumy.summarizers.luhn import LuhnSummarizer\n",
    "    \n",
    "    # Creating the parser\n",
    "    from sumy.nlp.tokenizers import Tokenizer\n",
    "    from sumy.parsers.plaintext import PlaintextParser\n",
    "    parser=PlaintextParser.from_string(text,Tokenizer('english'))\n",
    "    \n",
    "    # Creating the summarizer\n",
    "    luhn_summarizer=LuhnSummarizer()\n",
    "    luhn_summary=luhn_summarizer(parser.document,sentences_count=3)\n",
    "\n",
    "    \n",
    "    response = []\n",
    "    texto = ''\n",
    "    # Printing the summary\n",
    "    for sentence in luhn_summary:\n",
    "        response.append(sentence)\n",
    "    \n",
    "    for i in response:\n",
    "        texto = texto + str(i)\n",
    "    \n",
    "    return texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9176ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Latent Semantic Analysis, LSA\n",
    "def LSASummy(text):\n",
    "    # Importing the parser and tokenizer\n",
    "    from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "    # Parsing the text string using PlaintextParser\n",
    "    from sumy.nlp.tokenizers import Tokenizer\n",
    "    from sumy.parsers.plaintext import PlaintextParser\n",
    "    parser=PlaintextParser.from_string(text,Tokenizer('english'))\n",
    "    \n",
    "    # creating the summarizer\n",
    "    lsa_summarizer=LsaSummarizer()\n",
    "    lsa_summary= lsa_summarizer(parser.document,3)\n",
    "    \n",
    "    response = []\n",
    "    texto = ''\n",
    "    # Printing the summary\n",
    "    for sentence in lsa_summary:\n",
    "        response.append(sentence)\n",
    "    \n",
    "    for i in response:\n",
    "        texto = texto + str(i)\n",
    "    \n",
    "    return texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "658b9d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Envisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100 institutions with AI infrastructure, course content and curriculum, developer support, development tools and give students access to cloud and AI services.As part of the program, the Redmond giant which wants to expand its reach and is planning to build a strong developer ecosystem in India with the program will set up the core AI infrastructure and IoT Hub for the selected campuses.The company will provide AI development tools and Azure AI services such as Microsoft Cognitive Services, Bot Services and Azure Machine Learning.According to Manish Prakash, Country General Manager-PS, Health and Education, Microsoft India, said, \"With AI being the defining technology of our time, it is transforming lives and industry and the jobs of tomorrow will require a different skillset.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####Testing\n",
    "LuhnSummy(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64eff9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T5Transformer\n",
    "def T5Transformer(text):\n",
    "    # Importing requirements\n",
    "    from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration\n",
    "    \n",
    "    # Instantiating the model and tokenizer\n",
    "    my_model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "    tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "    \n",
    "    # Concatenating the word \"summarize:\" to raw text\n",
    "    textoserone = \"summarize:\" + text\n",
    "    \n",
    "    # encoding the input text\n",
    "    input_ids=tokenizer.encode(textoserone, return_tensors='pt', max_length=512)\n",
    "    \n",
    "    # Generating summary ids\n",
    "    summary_ids = my_model.generate(input_ids)\n",
    "    \n",
    "    # Decoding the tensor and printing the summary.\n",
    "    t5_summary = tokenizer.decode(summary_ids[0])\n",
    "    \n",
    "    return t5_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e92e0486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BARTTransformer\n",
    "def BARTTransformer(text):\n",
    "    # Importing the model\n",
    "    from transformers import BartForConditionalGeneration, BartTokenizer, BartConfig\n",
    "    \n",
    "    # Loading the model and tokenizer for bart-large-cnn\n",
    "    tokenizer=BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "    model=BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
    "    \n",
    "    # Encoding the inputs and passing them to model.generate()\n",
    "    inputs = tokenizer.batch_encode_plus([text],return_tensors='pt')\n",
    "    summary_ids = model.generate(inputs['input_ids'], early_stopping=True)\n",
    "    \n",
    "    # Decoding and printing the summary\n",
    "    bart_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return bart_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fcf3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT-2\n",
    "def gpt2(text):\n",
    "    # Importing model and tokenizer\n",
    "    from transformers import GPT2Tokenizer,GPT2LMHeadModel\n",
    "\n",
    "    # Instantiating the model and tokenizer with gpt-2\n",
    "    tokenizer=GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model=GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "    # Encoding text to get input ids & pass them to model.generate()\n",
    "    inputs=tokenizer.batch_encode_plus([text],return_tensors='pt',max_length=512)\n",
    "    summary_ids=model.generate(inputs['input_ids'],early_stopping=True)\n",
    "    \n",
    "    # Decoding and printing summary\n",
    "    GPT_summary=tokenizer.decode(summary_ids[0],skip_special_tokens=True)\n",
    "    \n",
    "    return GPT_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f80b12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XLM\n",
    "def XLM(text):\n",
    "    # Importing model and tokenizer\n",
    "    from transformers import XLMWithLMHeadModel, XLMTokenizer\n",
    "\n",
    "    # Instantiating the model and tokenizer\n",
    "    tokenizer=XLMTokenizer.from_pretrained('xlm-mlm-en-2048')\n",
    "    model=XLMWithLMHeadModel.from_pretrained('xlm-mlm-en-2048')\n",
    "\n",
    "    # Encoding text to get input ids & pass them to model.generate()\n",
    "    inputs=tokenizer.batch_encode_plus([text],return_tensors='pt',max_length=512)\n",
    "    summary_ids=model.generate(inputs['input_ids'],early_stopping=True)\n",
    "\n",
    "    # Decode and print the summary\n",
    "    XLM_summary=tokenizer.decode(summary_ids[0],skip_special_tokens=True)\n",
    "    \n",
    "    return XLM_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46cb368",
   "metadata": {},
   "source": [
    "# <font color='Red'><center>II- Visualization</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cc0a1b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv (r'dataset/cancer.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99f20e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scattertext\n",
    "Description_Scattertext='''\n",
    "Scattertext is a Python package that lets you interactively visualize how two categories of text are different from each other (Kessler 2017). \n",
    "Most of the work I‚Äôve done on Scattertext focuses on how you can visualize the differences in how single words and (and bigrams) are used with different frequencies across categories.\n",
    "'''\n",
    "\n",
    "def scattertextvisualizer():\n",
    "    import pytextrank, spacy\n",
    "    import scattertext as st\n",
    "    import numpy as np\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    nlp.add_pipe(\"textrank\", last=True)\n",
    "    \n",
    "    corpus = st.CorpusFromParsedDocuments(\n",
    "        df,\n",
    "        category_col='cancer',\n",
    "        parsed_col='parse',\n",
    "        feats_from_spacy_doc=st.PyTextRankPhrases()\n",
    "    ).build(\n",
    "    ).compact(\n",
    "        st.AssociationCompactor(2000, use_non_text_features=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52a4a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTextRank\n",
    "Description_PyTextRank='''\n",
    "PyTextRank, created by Paco Nathan, is an implementation of a modified version of the TextRank algorithm (Mihalcea and Tarau 2004). \n",
    "It involves graph centrality algorithm to extract a scored list of the most prominent phrases in a document. Here, named entities recognized by spaCy. \n",
    "As of spaCy version 2.2, these are from an NER system trained on Ontonotes 5.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5aee85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phrasemachine\n",
    "Description_Phrasemachine='''\n",
    "Phrasemachine from AbeHandler (Handler et al. 2016) uses regular expressions over sequences of part-of-speech tags to identify noun phrases. \n",
    "This has the advantage over using spaCy‚Äôs NP-chunking in that it tends to isolote meaningful, large noun phases which are free of appositives.\n",
    "'''\n",
    "\n",
    "category='democrat'\n",
    "category_name='Democratic'\n",
    "not_category_name='Republican'\n",
    "\n",
    "\n",
    "\n",
    "def phrasemachinevisualizer():\n",
    "    import spacy\n",
    "    from scattertext import SampleCorpora, PhraseMachinePhrases, dense_rank, RankDifference, AssociationCompactor, produce_scattertext_explorer\n",
    "    from scattertext.CorpusFromPandas import CorpusFromPandas\n",
    "    \n",
    "    corpus = CorpusFromPandas(\n",
    "        SampleCorpora.ConventionData2012.get_data(),\n",
    "        category_col='party',\n",
    "        text_col='text',\n",
    "        feats_from_spacy_doc=PhraseMachinePhrases(),\n",
    "        nlp=spacy.load('en', parser=False)\n",
    "    ).build().compact(AssociationCompactor(4000))\n",
    "    \n",
    "    html = produce_scattertext_explorer(\n",
    "        corpus,\n",
    "        category='democrat',\n",
    "        category_name='Democratic',\n",
    "        not_category_name='Republican',\n",
    "        minimum_term_frequency=0, \n",
    "        pmi_threshold_coefficient=0,\n",
    "        transform=st.dense_rank,\n",
    "        metadata=corpus.get_df()['speaker'],\n",
    "        term_scorer=st.RankDifference(),\n",
    "        width_in_pixels=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "669d434d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Have you thought about making a video and leaving it with your mum or so, perhaps for the young ones you think might forget you or just the whole family in general sharing your favourite memories from them all??How's your appetite? You should try a bunch of foods you haven't tried, or pig out on fancy desserts. Scrape every bit of endorphins outta this time as you can. \\\\*hugs\\\\*I‚Äôm so sorry to hear this. Spend as much time as you can with your children. Tell them everything you‚Äôve ever wanted to say. Arrange delivery of cards for their future birthdays. Make recordings. I looked through your post history. You‚Äôve been a wonderful father, and I hope that my 1 year old son will beat his cancer and grow up to be like your son. Your kids are old enough to remember you and manage the emotions that they will be feeling. They will carry on your legacy.  Well I am crying.  What a beautiful sentiment for your sons to read to him,  you must be so proud of their strength and compassion to have done this when facing something so heartbreaking.  \\nI am sorry you lost your husband to this horrendous disease. Please be kind to yourself throughout the coming days,  weeks and months.I am sorry for your loss. Words may seem shallow as they sometimes do for me, but I‚Äôm truly sorry. Try to have some peace.This is so painfully, agonizingly full of love. Im so sorry you are losing your husband. Etch the feelings of your legs entwined and your head on the pillow next to his into your brain. There will come a time when these memories albring nothing bit peace and happiness. You are in my thoughts. üíïüíîCongrats! Now go live this beautiful life!A beautiful read. You‚Äôre a wonderful person for staying with him and being his friend until the end. Internet hugs to you, I wish you all the best. And truly, do all the things you want to do, see all the places you want to see, and remember to take your friend with you in memory ‚ù§Ô∏èI was sitting right in your shoes last year. In the middle of May, we was at Disney. I had to push her around in a wheel ch..\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "92611b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rmastour\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2021-11-09 01:50:33.158 collecting all words and their counts\n",
      "2021-11-09 01:50:33.160 PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2021-11-09 01:50:33.185 collected 10551 word types from a corpus of 14434 words (unigram + bigrams) and 71 sentences\n",
      "2021-11-09 01:50:33.187 using 10551 counts as vocab in Phrases<0 vocab, min_count=5, threshold=100, max_vocab_size=40000000>\n",
      "2021-11-09 01:50:33.188 collecting all words and their counts\n",
      "2021-11-09 01:50:33.191 PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2021-11-09 01:50:33.273 collected 10560 word types from a corpus of 14391 words (unigram + bigrams) and 71 sentences\n",
      "2021-11-09 01:50:33.273 using 10560 counts as vocab in Phrases<0 vocab, min_count=5, threshold=100, max_vocab_size=40000000>\n",
      "2021-11-09 01:50:33.274 source_vocab length 10551\n",
      "2021-11-09 01:50:33.364 Phraser built with 4 phrasegrams\n",
      "2021-11-09 01:50:33.365 source_vocab length 10560\n",
      "2021-11-09 01:50:33.449 Phraser built with 6 phrasegrams\n",
      "2021-11-09 01:50:34.641 adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2021-11-09 01:50:34.654 built Dictionary(1300 unique tokens: ['activity', 'age', 'ago', 'allow', 'askreddit']...) from 71 documents (total 6039 corpus positions)\n",
      "2021-11-09 01:50:34.658 using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "2021-11-09 01:50:34.660 using symmetric eta at 0.2\n",
      "2021-11-09 01:50:34.661 using serial LDA version on this node\n",
      "2021-11-09 01:50:34.663 running online (multi-pass) LDA training, 5 topics, 10 passes over the supplied corpus of 71 documents, updating model once every 71 documents, evaluating perplexity every 71 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2021-11-09 01:50:34.743 -8.450 per-word bound, 349.6 perplexity estimate based on a held-out corpus of 71 documents with 6039 words\n",
      "2021-11-09 01:50:34.743 PROGRESS: pass 0, at document #71/71\n",
      "2021-11-09 01:50:34.798 optimized alpha [0.23017877, 0.30788156, 0.17249283, 0.20632349, 0.2728087]\n",
      "2021-11-09 01:50:34.799 topic #0 (0.230): 0.033*\"congratulation\" + 0.025*\"congrat\" + 0.022*\"cancer\" + 0.022*\"happy\" + 0.020*\"good\" + 0.019*\"sorry\" + 0.017*\"news\" + 0.017*\"hope\" + 0.016*\"thank\" + 0.012*\"get\"\n",
      "2021-11-09 01:50:34.800 topic #1 (0.308): 0.036*\"sorry\" + 0.025*\"thank\" + 0.021*\"congratulation\" + 0.018*\"cancer\" + 0.014*\"congrat\" + 0.014*\"loss\" + 0.014*\"happy\" + 0.013*\"good\" + 0.013*\"news\" + 0.012*\"love\"\n",
      "2021-11-09 01:50:34.802 topic #2 (0.172): 0.034*\"sorry\" + 0.024*\"cancer\" + 0.012*\"love\" + 0.012*\"loss\" + 0.011*\"fuck\" + 0.009*\"go\" + 0.008*\"wish\" + 0.008*\"thank\" + 0.007*\"know\" + 0.007*\"good\"\n",
      "2021-11-09 01:50:34.804 topic #3 (0.206): 0.083*\"sorry\" + 0.046*\"loss\" + 0.019*\"cancer\" + 0.019*\"love\" + 0.017*\"thank\" + 0.012*\"read\" + 0.012*\"go\" + 0.011*\"hear\" + 0.010*\"heart\" + 0.010*\"body\"\n",
      "2021-11-09 01:50:34.805 topic #4 (0.273): 0.054*\"congratulation\" + 0.042*\"news\" + 0.040*\"congrat\" + 0.030*\"good\" + 0.024*\"happy\" + 0.020*\"cancer\" + 0.020*\"awesome\" + 0.014*\"hear\" + 0.014*\"amazing\" + 0.014*\"fuck\"\n",
      "2021-11-09 01:50:34.807 topic diff=2.335772, rho=1.000000\n",
      "2021-11-09 01:50:34.870 -6.379 per-word bound, 83.2 perplexity estimate based on a held-out corpus of 71 documents with 6039 words\n",
      "2021-11-09 01:50:34.871 PROGRESS: pass 1, at document #71/71\n",
      "2021-11-09 01:50:34.903 optimized alpha [0.10169381, 0.123145446, 0.08989854, 0.13991687, 0.18013665]\n",
      "2021-11-09 01:50:34.906 topic #0 (0.102): 0.026*\"congratulation\" + 0.022*\"cancer\" + 0.021*\"happy\" + 0.020*\"congrat\" + 0.017*\"good\" + 0.016*\"thank\" + 0.015*\"news\" + 0.015*\"sorry\" + 0.015*\"dad\" + 0.015*\"hope\"\n",
      "2021-11-09 01:50:34.907 topic #1 (0.123): 0.029*\"sorry\" + 0.027*\"thank\" + 0.016*\"cancer\" + 0.013*\"good\" + 0.013*\"congratulation\" + 0.012*\"love\" + 0.011*\"body\" + 0.010*\"read\" + 0.009*\"share\" + 0.009*\"congrat\"\n",
      "2021-11-09 01:50:34.908 topic #2 (0.090): 0.026*\"sorry\" + 0.019*\"cancer\" + 0.014*\"love\" + 0.014*\"fuck\" + 0.012*\"wish\" + 0.009*\"enjoy\" + 0.009*\"send\" + 0.008*\"friend\" + 0.008*\"hope\" + 0.008*\"go\"\n",
      "2021-11-09 01:50:34.910 topic #3 (0.140): 0.091*\"sorry\" + 0.049*\"loss\" + 0.022*\"cancer\" + 0.019*\"love\" + 0.017*\"thank\" + 0.013*\"go\" + 0.012*\"read\" + 0.012*\"heart\" + 0.010*\"fuck\" + 0.010*\"send\"\n",
      "2021-11-09 01:50:34.911 topic #4 (0.180): 0.064*\"congratulation\" + 0.046*\"congrat\" + 0.046*\"news\" + 0.031*\"good\" + 0.030*\"happy\" + 0.022*\"awesome\" + 0.020*\"cancer\" + 0.018*\"amazing\" + 0.017*\"great\" + 0.015*\"hear\"\n",
      "2021-11-09 01:50:34.912 topic diff=0.565550, rho=0.577350\n",
      "2021-11-09 01:50:34.968 -6.170 per-word bound, 72.0 perplexity estimate based on a held-out corpus of 71 documents with 6039 words\n",
      "2021-11-09 01:50:34.968 PROGRESS: pass 2, at document #71/71\n",
      "2021-11-09 01:50:34.993 optimized alpha [0.07560067, 0.09181245, 0.06753443, 0.11074744, 0.15014178]\n",
      "2021-11-09 01:50:34.995 topic #0 (0.076): 0.022*\"cancer\" + 0.019*\"happy\" + 0.019*\"congratulation\" + 0.017*\"dad\" + 0.017*\"congrat\" + 0.016*\"thank\" + 0.015*\"good\" + 0.014*\"sorry\" + 0.013*\"news\" + 0.012*\"hope\"\n",
      "2021-11-09 01:50:34.995 topic #1 (0.092): 0.028*\"thank\" + 0.025*\"sorry\" + 0.016*\"cancer\" + 0.013*\"good\" + 0.011*\"love\" + 0.011*\"read\" + 0.010*\"body\" + 0.010*\"nurse\" + 0.010*\"share\" + 0.009*\"year\"\n",
      "2021-11-09 01:50:34.996 topic #2 (0.068): 0.024*\"sorry\" + 0.017*\"cancer\" + 0.015*\"fuck\" + 0.015*\"love\" + 0.013*\"wish\" + 0.011*\"enjoy\" + 0.009*\"send\" + 0.009*\"friend\" + 0.009*\"hope\" + 0.008*\"peace\"\n",
      "2021-11-09 01:50:34.998 topic #3 (0.111): 0.093*\"sorry\" + 0.049*\"loss\" + 0.023*\"cancer\" + 0.019*\"love\" + 0.017*\"thank\" + 0.013*\"go\" + 0.012*\"heart\" + 0.012*\"read\" + 0.011*\"send\" + 0.010*\"wife\"\n",
      "2021-11-09 01:50:34.998 topic #4 (0.150): 0.068*\"congratulation\" + 0.048*\"congrat\" + 0.047*\"news\" + 0.032*\"happy\" + 0.031*\"good\" + 0.023*\"awesome\" + 0.020*\"cancer\" + 0.019*\"amazing\" + 0.018*\"great\" + 0.015*\"hear\"\n",
      "2021-11-09 01:50:35.000 topic diff=0.337792, rho=0.500000\n",
      "2021-11-09 01:50:35.060 -6.101 per-word bound, 68.7 perplexity estimate based on a held-out corpus of 71 documents with 6039 words\n",
      "2021-11-09 01:50:35.061 PROGRESS: pass 3, at document #71/71\n",
      "2021-11-09 01:50:35.081 optimized alpha [0.062410157, 0.0764213, 0.055302832, 0.09504868, 0.1340635]\n",
      "2021-11-09 01:50:35.083 topic #0 (0.062): 0.022*\"cancer\" + 0.019*\"dad\" + 0.016*\"happy\" + 0.015*\"thank\" + 0.014*\"congratulation\" + 0.014*\"sorry\" + 0.013*\"stage\" + 0.013*\"congrat\" + 0.013*\"good\" + 0.011*\"get\"\n",
      "2021-11-09 01:50:35.084 topic #1 (0.076): 0.028*\"thank\" + 0.022*\"sorry\" + 0.015*\"cancer\" + 0.013*\"good\" + 0.011*\"love\" + 0.011*\"read\" + 0.011*\"nurse\" + 0.010*\"body\" + 0.010*\"share\" + 0.010*\"fight\"\n",
      "2021-11-09 01:50:35.085 topic #2 (0.055): 0.022*\"sorry\" + 0.016*\"cancer\" + 0.016*\"fuck\" + 0.015*\"love\" + 0.013*\"wish\" + 0.012*\"enjoy\" + 0.010*\"send\" + 0.009*\"friend\" + 0.009*\"hope\" + 0.008*\"peace\"\n",
      "2021-11-09 01:50:35.087 topic #3 (0.095): 0.093*\"sorry\" + 0.049*\"loss\" + 0.023*\"cancer\" + 0.019*\"love\" + 0.017*\"thank\" + 0.013*\"go\" + 0.012*\"heart\" + 0.012*\"read\" + 0.011*\"send\" + 0.010*\"wife\"\n",
      "2021-11-09 01:50:35.088 topic #4 (0.134): 0.069*\"congratulation\" + 0.050*\"congrat\" + 0.048*\"news\" + 0.033*\"happy\" + 0.032*\"good\" + 0.024*\"awesome\" + 0.020*\"cancer\" + 0.020*\"amazing\" + 0.019*\"great\" + 0.015*\"hear\"\n",
      "2021-11-09 01:50:35.089 topic diff=0.207788, rho=0.447214\n",
      "2021-11-09 01:50:35.148 -6.072 per-word bound, 67.3 perplexity estimate based on a held-out corpus of 71 documents with 6039 words\n",
      "2021-11-09 01:50:35.149 PROGRESS: pass 4, at document #71/71\n",
      "2021-11-09 01:50:35.169 optimized alpha [0.054091908, 0.06681604, 0.04758102, 0.084832616, 0.12291619]\n",
      "2021-11-09 01:50:35.171 topic #0 (0.054): 0.021*\"cancer\" + 0.020*\"dad\" + 0.014*\"stage\" + 0.014*\"sorry\" + 0.014*\"thank\" + 0.013*\"happy\" + 0.011*\"good\" + 0.010*\"congratulation\" + 0.010*\"get\" + 0.010*\"congrat\"\n",
      "2021-11-09 01:50:35.173 topic #1 (0.067): 0.029*\"thank\" + 0.021*\"sorry\" + 0.015*\"cancer\" + 0.013*\"good\" + 0.011*\"nurse\" + 0.011*\"love\" + 0.011*\"read\" + 0.010*\"body\" + 0.010*\"fight\" + 0.010*\"share\"\n",
      "2021-11-09 01:50:35.174 topic #2 (0.048): 0.022*\"sorry\" + 0.016*\"fuck\" + 0.016*\"cancer\" + 0.015*\"love\" + 0.014*\"wish\" + 0.012*\"enjoy\" + 0.010*\"send\" + 0.010*\"friend\" + 0.010*\"hope\" + 0.008*\"peace\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 01:50:35.175 topic #3 (0.085): 0.094*\"sorry\" + 0.049*\"loss\" + 0.024*\"cancer\" + 0.019*\"love\" + 0.017*\"thank\" + 0.013*\"go\" + 0.012*\"heart\" + 0.012*\"read\" + 0.011*\"send\" + 0.010*\"wife\"\n",
      "2021-11-09 01:50:35.177 topic #4 (0.123): 0.070*\"congratulation\" + 0.050*\"congrat\" + 0.049*\"news\" + 0.034*\"happy\" + 0.032*\"good\" + 0.024*\"awesome\" + 0.020*\"cancer\" + 0.020*\"amazing\" + 0.020*\"great\" + 0.015*\"hear\"\n",
      "2021-11-09 01:50:35.177 topic diff=0.131388, rho=0.408248\n",
      "2021-11-09 01:50:35.229 -6.057 per-word bound, 66.6 perplexity estimate based on a held-out corpus of 71 documents with 6039 words\n",
      "2021-11-09 01:50:35.230 PROGRESS: pass 5, at document #71/71\n",
      "2021-11-09 01:50:35.250 optimized alpha [0.04826741, 0.06012559, 0.04217103, 0.077903286, 0.11459062]\n",
      "2021-11-09 01:50:35.252 topic #0 (0.048): 0.021*\"dad\" + 0.021*\"cancer\" + 0.015*\"sorry\" + 0.015*\"stage\" + 0.012*\"thank\" + 0.011*\"happy\" + 0.010*\"good\" + 0.010*\"get\" + 0.009*\"body\" + 0.009*\"diagnose\"\n",
      "2021-11-09 01:50:35.254 topic #1 (0.060): 0.029*\"thank\" + 0.020*\"sorry\" + 0.015*\"cancer\" + 0.013*\"good\" + 0.012*\"nurse\" + 0.011*\"love\" + 0.011*\"read\" + 0.011*\"fight\" + 0.010*\"body\" + 0.010*\"share\"\n",
      "2021-11-09 01:50:35.256 topic #2 (0.042): 0.021*\"sorry\" + 0.016*\"fuck\" + 0.016*\"cancer\" + 0.015*\"love\" + 0.014*\"wish\" + 0.012*\"enjoy\" + 0.010*\"send\" + 0.010*\"friend\" + 0.010*\"hope\" + 0.008*\"peace\"\n",
      "2021-11-09 01:50:35.258 topic #3 (0.078): 0.094*\"sorry\" + 0.049*\"loss\" + 0.024*\"cancer\" + 0.019*\"love\" + 0.017*\"thank\" + 0.013*\"go\" + 0.012*\"heart\" + 0.012*\"read\" + 0.011*\"send\" + 0.010*\"wife\"\n",
      "2021-11-09 01:50:35.259 topic #4 (0.115): 0.071*\"congratulation\" + 0.051*\"congrat\" + 0.049*\"news\" + 0.035*\"happy\" + 0.032*\"good\" + 0.024*\"awesome\" + 0.020*\"cancer\" + 0.020*\"great\" + 0.020*\"amazing\" + 0.015*\"hope\"\n",
      "2021-11-09 01:50:35.260 topic diff=0.085641, rho=0.377964\n",
      "2021-11-09 01:50:35.313 -6.048 per-word bound, 66.2 perplexity estimate based on a held-out corpus of 71 documents with 6039 words\n",
      "2021-11-09 01:50:35.314 PROGRESS: pass 6, at document #71/71\n",
      "2021-11-09 01:50:35.331 optimized alpha [0.043919653, 0.055140667, 0.038130853, 0.07235155, 0.10874981]\n",
      "2021-11-09 01:50:35.333 topic #0 (0.044): 0.022*\"dad\" + 0.021*\"cancer\" + 0.016*\"sorry\" + 0.015*\"stage\" + 0.011*\"thank\" + 0.010*\"get\" + 0.009*\"diagnose\" + 0.009*\"good\" + 0.009*\"body\" + 0.008*\"happy\"\n",
      "2021-11-09 01:50:35.334 topic #1 (0.055): 0.029*\"thank\" + 0.019*\"sorry\" + 0.014*\"cancer\" + 0.013*\"good\" + 0.012*\"nurse\" + 0.011*\"love\" + 0.011*\"read\" + 0.011*\"fight\" + 0.010*\"body\" + 0.010*\"share\"\n",
      "2021-11-09 01:50:35.335 topic #2 (0.038): 0.020*\"sorry\" + 0.017*\"fuck\" + 0.016*\"cancer\" + 0.015*\"love\" + 0.014*\"wish\" + 0.013*\"enjoy\" + 0.010*\"send\" + 0.010*\"friend\" + 0.010*\"hope\" + 0.008*\"peace\"\n",
      "2021-11-09 01:50:35.336 topic #3 (0.072): 0.094*\"sorry\" + 0.049*\"loss\" + 0.024*\"cancer\" + 0.019*\"love\" + 0.017*\"thank\" + 0.013*\"go\" + 0.012*\"heart\" + 0.012*\"read\" + 0.011*\"send\" + 0.010*\"wife\"\n",
      "2021-11-09 01:50:35.337 topic #4 (0.109): 0.071*\"congratulation\" + 0.051*\"congrat\" + 0.049*\"news\" + 0.036*\"happy\" + 0.032*\"good\" + 0.024*\"awesome\" + 0.021*\"cancer\" + 0.020*\"great\" + 0.020*\"amazing\" + 0.015*\"thank\"\n",
      "2021-11-09 01:50:35.338 topic diff=0.057669, rho=0.353553\n",
      "2021-11-09 01:50:35.390 -6.042 per-word bound, 65.9 perplexity estimate based on a held-out corpus of 71 documents with 6039 words\n",
      "2021-11-09 01:50:35.391 PROGRESS: pass 7, at document #71/71\n",
      "2021-11-09 01:50:35.409 optimized alpha [0.04051213, 0.050952554, 0.034965813, 0.067952946, 0.10385012]\n",
      "2021-11-09 01:50:35.411 topic #0 (0.041): 0.022*\"dad\" + 0.021*\"cancer\" + 0.017*\"sorry\" + 0.015*\"stage\" + 0.010*\"diagnose\" + 0.009*\"thank\" + 0.009*\"get\" + 0.009*\"man\" + 0.008*\"good\" + 0.008*\"body\"\n",
      "2021-11-09 01:50:35.412 topic #1 (0.051): 0.029*\"thank\" + 0.019*\"sorry\" + 0.014*\"cancer\" + 0.013*\"good\" + 0.012*\"nurse\" + 0.011*\"love\" + 0.011*\"read\" + 0.011*\"fight\" + 0.010*\"share\" + 0.010*\"body\"\n",
      "2021-11-09 01:50:35.412 topic #2 (0.035): 0.019*\"sorry\" + 0.017*\"fuck\" + 0.015*\"love\" + 0.015*\"cancer\" + 0.014*\"wish\" + 0.013*\"enjoy\" + 0.010*\"send\" + 0.010*\"friend\" + 0.010*\"hope\" + 0.008*\"peace\"\n",
      "2021-11-09 01:50:35.413 topic #3 (0.068): 0.094*\"sorry\" + 0.049*\"loss\" + 0.024*\"cancer\" + 0.019*\"love\" + 0.017*\"thank\" + 0.013*\"go\" + 0.012*\"heart\" + 0.012*\"read\" + 0.011*\"send\" + 0.010*\"wife\"\n",
      "2021-11-09 01:50:35.414 topic #4 (0.104): 0.071*\"congratulation\" + 0.051*\"congrat\" + 0.049*\"news\" + 0.036*\"happy\" + 0.032*\"good\" + 0.024*\"awesome\" + 0.021*\"cancer\" + 0.020*\"great\" + 0.020*\"amazing\" + 0.016*\"thank\"\n",
      "2021-11-09 01:50:35.415 topic diff=0.040246, rho=0.333333\n",
      "2021-11-09 01:50:35.466 -6.038 per-word bound, 65.7 perplexity estimate based on a held-out corpus of 71 documents with 6039 words\n",
      "2021-11-09 01:50:35.467 PROGRESS: pass 8, at document #71/71\n",
      "2021-11-09 01:50:35.488 optimized alpha [0.037758026, 0.047605067, 0.03240855, 0.064366646, 0.09967777]\n",
      "2021-11-09 01:50:35.490 topic #0 (0.038): 0.023*\"dad\" + 0.020*\"cancer\" + 0.018*\"sorry\" + 0.015*\"stage\" + 0.010*\"diagnose\" + 0.009*\"get\" + 0.009*\"man\" + 0.008*\"thank\" + 0.008*\"read\" + 0.008*\"body\"\n",
      "2021-11-09 01:50:35.491 topic #1 (0.048): 0.030*\"thank\" + 0.018*\"sorry\" + 0.014*\"cancer\" + 0.013*\"good\" + 0.012*\"nurse\" + 0.011*\"love\" + 0.011*\"read\" + 0.011*\"fight\" + 0.010*\"share\" + 0.010*\"body\"\n",
      "2021-11-09 01:50:35.492 topic #2 (0.032): 0.018*\"sorry\" + 0.017*\"fuck\" + 0.015*\"love\" + 0.015*\"cancer\" + 0.014*\"wish\" + 0.013*\"enjoy\" + 0.010*\"friend\" + 0.010*\"send\" + 0.010*\"hope\" + 0.008*\"peace\"\n",
      "2021-11-09 01:50:35.493 topic #3 (0.064): 0.095*\"sorry\" + 0.049*\"loss\" + 0.024*\"cancer\" + 0.019*\"love\" + 0.017*\"thank\" + 0.013*\"go\" + 0.012*\"heart\" + 0.012*\"read\" + 0.011*\"send\" + 0.010*\"wife\"\n",
      "2021-11-09 01:50:35.494 topic #4 (0.100): 0.071*\"congratulation\" + 0.051*\"congrat\" + 0.049*\"news\" + 0.036*\"happy\" + 0.032*\"good\" + 0.024*\"awesome\" + 0.021*\"cancer\" + 0.020*\"great\" + 0.020*\"amazing\" + 0.016*\"thank\"\n",
      "2021-11-09 01:50:35.495 topic diff=0.028689, rho=0.316228\n",
      "2021-11-09 01:50:35.544 -6.035 per-word bound, 65.6 perplexity estimate based on a held-out corpus of 71 documents with 6039 words\n",
      "2021-11-09 01:50:35.545 PROGRESS: pass 9, at document #71/71\n",
      "2021-11-09 01:50:35.561 optimized alpha [0.035476398, 0.04485465, 0.030290749, 0.06137067, 0.09606626]\n",
      "2021-11-09 01:50:35.563 topic #0 (0.035): 0.023*\"dad\" + 0.020*\"cancer\" + 0.018*\"sorry\" + 0.015*\"stage\" + 0.010*\"diagnose\" + 0.009*\"man\" + 0.009*\"get\" + 0.008*\"read\" + 0.008*\"body\" + 0.008*\"good\"\n",
      "2021-11-09 01:50:35.564 topic #1 (0.045): 0.030*\"thank\" + 0.018*\"sorry\" + 0.014*\"cancer\" + 0.013*\"good\" + 0.012*\"nurse\" + 0.011*\"love\" + 0.011*\"read\" + 0.011*\"fight\" + 0.010*\"share\" + 0.010*\"body\"\n",
      "2021-11-09 01:50:35.564 topic #2 (0.030): 0.017*\"sorry\" + 0.017*\"fuck\" + 0.015*\"love\" + 0.015*\"cancer\" + 0.014*\"wish\" + 0.013*\"enjoy\" + 0.010*\"friend\" + 0.010*\"send\" + 0.010*\"hope\" + 0.009*\"peace\"\n",
      "2021-11-09 01:50:35.566 topic #3 (0.061): 0.095*\"sorry\" + 0.049*\"loss\" + 0.024*\"cancer\" + 0.019*\"love\" + 0.017*\"thank\" + 0.013*\"go\" + 0.012*\"heart\" + 0.012*\"read\" + 0.011*\"send\" + 0.010*\"wife\"\n",
      "2021-11-09 01:50:35.567 topic #4 (0.096): 0.071*\"congratulation\" + 0.052*\"congrat\" + 0.049*\"news\" + 0.036*\"happy\" + 0.032*\"good\" + 0.024*\"awesome\" + 0.021*\"cancer\" + 0.020*\"great\" + 0.020*\"amazing\" + 0.016*\"thank\"\n",
      "2021-11-09 01:50:35.567 topic diff=0.021187, rho=0.301511\n",
      "2021-11-09 01:50:35.616 -6.033 per-word bound, 65.5 perplexity estimate based on a held-out corpus of 71 documents with 6039 words\n",
      "2021-11-09 01:50:35.619 using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.032702148232087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 01:50:38.447 7 accumulators retrieved from output queue\n",
      "2021-11-09 01:50:38.461 accumulated word occurrence stats for 426 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.3784475488646925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2247224492579238564881133034\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2247224492579238564881133034_data = {\"mdsDat\": {\"x\": [150.22215270996094, 51.16336441040039, -73.1445541381836, -66.4101333618164, 54.41732406616211], \"y\": [-72.2695541381836, -159.968017578125, 21.523815155029297, -110.60643768310547, 12.44344425201416], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [39.02517707605218, 33.559370234096576, 14.696392782095952, 7.3570463096994425, 5.36201359805585]}, \"tinfo\": {\"Term\": [\"congratulation\", \"sorry\", \"loss\", \"congrat\", \"news\", \"happy\", \"awesome\", \"dad\", \"stage\", \"cancer\", \"thank\", \"fuck\", \"enjoy\", \"love\", \"amazing\", \"wish\", \"read\", \"send\", \"nurse\", \"get\", \"diagnose\", \"great\", \"man\", \"peace\", \"good\", \"yay\", \"heart\", \"friend\", \"lose\", \"fight\", \"congratulation\", \"congrat\", \"news\", \"fantastic\", \"yay\", \"awesome\", \"ned\", \"happy\", \"kick\", \"incredible\", \"celebrate\", \"luck\", \"amazing\", \"woo\", \"excellent\", \"victory\", \"dance\", \"great\", \"hoo\", \"ass\", \"wonderful\", \"face\", \"omg\", \"ncongrat\", \"survivor\", \"mate\", \"super\", \"freak\", \"encourage\", \"bowel\", \"continue\", \"good\", \"beat\", \"long\", \"live\", \"hope\", \"hear\", \"day\", \"fuck\", \"body\", \"enjoy\", \"cancer\", \"life\", \"stage\", \"thank\", \"glad\", \"get\", \"wish\", \"mom\", \"post\", \"story\", \"love\", \"share\", \"go\", \"loss\", \"condolence\", \"deep\", \"andreas\", \"song\", \"gene\", \"analogy\", \"happen\", \"pain\", \"home\", \"heartbreake\", \"memory\", \"sorry\", \"wife\", \"strong\", \"deeply\", \"disease\", \"sympathy\", \"gorgeous\", \"thro\", \"picture\", \"single\", \"shed\", \"speechless\", \"ewe\", \"son\", \"heart\", \"terribly\", \"sharing\", \"hurt\", \"die\", \"pass\", \"break\", \"forget\", \"beautiful\", \"fair\", \"word\", \"cry\", \"strength\", \"think\", \"family\", \"love\", \"send\", \"go\", \"hug\", \"read\", \"say\", \"cancer\", \"lose\", \"peace\", \"thank\", \"know\", \"m\", \"share\", \"fuck\", \"story\", \"year\", \"hear\", \"body\", \"wish\", \"good\", \"hope\", \"friend\", \"oncology\", \"val\", \"nurse\", \"chem\", \"emotion\", \"saint\", \"energy\", \"number\", \"favorite\", \"advice\", \"keep\", \"learn\", \"stay_strong\", \"emotional\", \"mix\", \"allergic\", \"doctor\", \"humble\", \"incurable\", \"early\", \"depressing\", \"regard\", \"inevitability\", \"panpsychism\", \"user\", \"wha\", \"profile\", \"termin\", \"nbiggest\", \"wisdom\", \"dear\", \"fighting\", \"try\", \"appreciate\", \"sub\", \"state\", \"woman\", \"prayer\", \"pray\", \"fight\", \"ago\", \"old\", \"thank\", \"want\", \"give\", \"get\", \"year\", \"today\", \"share\", \"post\", \"read\", \"man\", \"month\", \"tell\", \"help\", \"feel\", \"say\", \"love\", \"cancer\", \"body\", \"sorry\", \"good\", \"wish\", \"know\", \"hope\", \"hear\", \"story\", \"send\", \"insurance\", \"pudding\", \"tak\", \"healthcare\", \"laugh\", \"funny\", \"humour\", \"health\", \"tea\", \"soul\", \"college\", \"feb\", \"find\", \"doubl\", \"ryan\", \"someday\", \"embrace\", \"rem\", \"fuckcancer\", \"professor\", \"pudd\", \"nlook\", \"brah\", \"afte\", \"conten\", \"arm\", \"strange\", \"pudde\", \"puddi\", \"fellow\", \"agree\", \"situation\", \"able\", \"hand\", \"enjoy\", \"hospice\", \"care\", \"peace\", \"wish\", \"fuck\", \"completely\", \"personally\", \"friend\", \"love\", \"send\", \"child\", \"shit\", \"seriously\", \"rest\", \"cancer\", \"lose\", \"think\", \"sorry\", \"hope\", \"hug\", \"know\", \"thing\", \"go\", \"body\", \"hear\", \"tell\", \"fight\", \"really\", \"diagnose\", \"crc\", \"clickbaite\", \"nyike\", \"dark\", \"ncongratula\", \"light\", \"chest\", \"mov\", \"fee\", \"barely\", \"dm\", \"fast\", \"sentence\", \"hoff\", \"drug\", \"hi\", \"allone\", \"lost\", \"remarkable\", \"ure\", \"occur\", \"courageous\", \"cong\", \"ball\", \"burkitt\", \"await\", \"doin\", \"scary\", \"cat\", \"king\", \"dad\", \"terminal\", \"stage\", \"actually\", \"diagnose\", \"man\", \"cancer\", \"add\", \"hard\", \"sure\", \"get\", \"similar\", \"sorry\", \"read\", \"situation\", \"really\", \"lung\", \"know\", \"body\", \"go\", \"dude\", \"imagine\", \"tell\", \"recently\", \"young\", \"fuck\", \"lose\", \"late\", \"people\", \"good\", \"thank\", \"life\", \"hear\", \"mom\", \"love\", \"hope\", \"happy\", \"feel\", \"pass\"], \"Freq\": [169.0, 222.0, 100.0, 124.0, 117.0, 91.0, 58.0, 20.0, 26.0, 122.0, 100.0, 65.0, 18.0, 68.0, 52.0, 46.0, 43.0, 37.0, 12.0, 34.0, 24.0, 55.0, 22.0, 18.0, 107.0, 23.0, 30.0, 30.0, 25.0, 19.0, 167.48163424210455, 121.5120571373293, 114.72916943872646, 19.171954791245334, 22.293062310819355, 56.31420032559701, 11.94934776878742, 85.72237778676511, 7.448869687283119, 6.440285066568212, 5.633807399515496, 25.586621261593955, 47.173163864556486, 4.69888447371805, 4.598228269497968, 3.8181777362233063, 3.816834471925295, 48.058072144016045, 3.765899074977907, 7.452205899265107, 27.82449958208093, 4.4948356032459476, 3.6838820346904226, 4.372724757514388, 7.34849031183687, 2.9128326891382197, 2.9120236028606796, 2.910647964137185, 2.911023562344697, 2.9089625734952973, 3.591771307000193, 75.4659666445987, 6.838971726640198, 6.334278028278661, 11.046187995422445, 36.735776391624995, 35.12650844971018, 13.235394933869545, 32.13952104156473, 30.19959498446133, 12.003645716232445, 48.85885520449819, 13.535166749709086, 14.855716272850998, 37.99476182931769, 11.202992153452234, 16.02585092288389, 16.979300799562896, 11.164490730766667, 12.61864347196757, 11.817909796202267, 12.654797474446072, 11.476888572544626, 11.336829125837594, 99.77795250811477, 13.50734040026195, 8.18147208970331, 5.4908908149720626, 11.631177269361256, 12.620315714177677, 5.42964209499835, 4.620541412708029, 3.737905791182853, 3.7374820552290746, 3.735727184391545, 3.72732914359269, 191.9944322380497, 21.03036456709904, 12.56814523030056, 5.68768785352305, 2.847568839477702, 2.847778112189841, 2.8464474491724077, 2.8458746034620654, 2.8436969404033934, 2.843406978550836, 2.8426019746119207, 2.8429657835432827, 2.8345417900969245, 2.8222466053757356, 25.23639973121339, 2.7992884215281455, 5.3668012980669, 6.599659639986291, 8.181095540381357, 11.973884338971722, 8.540836984080244, 7.252582008265938, 14.142956599453871, 4.62127516483289, 14.04796047226604, 9.568049378382716, 5.671928462226511, 12.558293605308371, 16.889390330943453, 37.94774223310987, 22.447430082332488, 26.9688776807451, 14.243937879022246, 24.178786877492065, 13.165360004781572, 48.34331584231222, 14.63802458456046, 11.615382959957167, 33.69063225870936, 18.10127138381922, 12.365214401478786, 17.211873210154206, 20.383928473229904, 14.598271734714116, 14.040226583310105, 17.60635911459765, 17.26719292983925, 15.17138357765949, 16.58661070171708, 14.99830961825796, 12.898928238049132, 5.475158973378777, 5.471540280920253, 10.787690865919972, 2.4294990294189427, 2.427800235980071, 1.6728536214315772, 1.6721768730418065, 1.6721704671791857, 1.6711606139331372, 1.6708493096738426, 1.6709343423341145, 1.6702183322057007, 1.6691115644574224, 1.6686671835682005, 1.6644811589862831, 1.651106234436023, 3.188639830858177, 1.636629088233538, 2.5876337407928256, 1.7128002707733552, 0.9142406837363639, 0.9142511190932138, 0.9142327280682704, 0.9142145436840566, 0.9141987356682346, 0.9141115332803007, 0.9141702192475358, 0.9141847874189798, 0.9141613336961587, 0.9141652598700231, 1.6720926669444534, 3.1863661629092777, 5.472107716364012, 1.6741157830085907, 2.5109489527193363, 1.6717646247860531, 1.6689336467891498, 6.999370338636745, 7.748831468374597, 9.42291067597403, 3.901546008871198, 4.669081176673075, 26.297502624449745, 5.888363149147808, 6.7617062229043094, 8.969408664943096, 8.955152934282484, 4.6693655143171435, 9.119190131459545, 8.031060550437262, 9.58792982989863, 6.297934580888695, 4.675572588555902, 6.176908825035972, 3.314639015793343, 6.069768086374776, 5.4986048438521085, 9.911168004614831, 12.498767856327985, 8.973429893543075, 16.21502366897238, 11.346752400748432, 7.591105905645522, 6.402751851185133, 6.496456396319713, 6.215446907843743, 5.527642825752607, 5.530772606244658, 2.5965923477043265, 1.3631288577177372, 1.3622120264518305, 1.3618523488808547, 1.3619118296410824, 1.3609907571383593, 1.3603406065678727, 1.9804947710598573, 1.982797245427064, 0.7445002971419876, 0.7442327371657643, 0.7440246579497685, 0.7438091824305443, 0.7437609771535599, 0.743929643900605, 0.7438147167273654, 0.7438722837587856, 0.7437930450416825, 0.7436795660956484, 0.7436869623988768, 0.7438210268601896, 0.743669738839611, 0.743887024642842, 0.7436837038876644, 0.7437299437134411, 0.7437003067781278, 0.7438224750873951, 0.743827130103413, 0.7438254749866066, 0.7438068549225354, 2.596908888793537, 2.598616348668868, 1.360822762782517, 1.3457567517184919, 5.700217729431168, 1.9646826126505785, 1.9758846500854244, 3.7787586990675126, 6.221248086284821, 7.4076250548033125, 1.3611712683150499, 1.3644638128668432, 4.433834069611465, 6.847661799093547, 4.416859605424941, 1.3483914907845693, 1.979613835139688, 1.3645069493486082, 1.3440476367263547, 6.632083248848196, 3.070561733955579, 2.5558518544061006, 7.709849383639269, 4.262988361290809, 2.607316883940546, 3.1122272306589425, 1.9861128581693457, 2.5251649543687287, 2.5407915328060975, 2.377347506843352, 2.0012002823070523, 1.960396273901384, 1.928176528811749, 1.9591507985046204, 1.1673262942033422, 0.6397256104259156, 0.6396508202147634, 0.6395699231416119, 0.6395540151430704, 0.6395482098545032, 0.6395329050028259, 0.6394891014618184, 0.639269631396633, 0.6391342249256357, 0.6391086665772682, 0.6393535442041051, 0.6391216342348469, 0.6389763512339496, 0.6389516976058782, 0.6387784436691567, 0.6387153394284971, 0.6387393145163462, 0.6384716680953884, 0.638696114122203, 0.6386936261413884, 0.6385474384201948, 0.6385225586120494, 0.6384129366694937, 0.6384213807255915, 0.6383407098325141, 0.6382279213689217, 0.6381927880640861, 0.6369614637409639, 0.6371896794356792, 7.4175411490627825, 1.685581066534352, 4.833949795196237, 1.6455517170291758, 3.273472244926091, 2.903736582598632, 6.52798155244392, 1.16626143841472, 1.7063600791505094, 1.7053991154092336, 2.8101764410347196, 1.1722750388301744, 5.822934835059248, 2.684955914278873, 1.1767574755376757, 1.8528805866264062, 1.1667273693672608, 2.223656526507774, 2.5050249909847673, 2.287782950315405, 1.1608466120486312, 1.4034630412919604, 1.711217823994216, 1.1723724470487316, 1.0884567746289808, 2.3383972257126384, 1.7041634182713463, 1.0125885892438906, 1.166437331118972, 2.4288445263107734, 2.352416922209202, 1.3466541460266757, 1.4886465284201134, 1.2907385112671679, 1.3956634476184577, 1.3607887420008562, 1.3519947099351186, 1.1880810301582185, 1.179482191496385], \"Total\": [169.0, 222.0, 100.0, 124.0, 117.0, 91.0, 58.0, 20.0, 26.0, 122.0, 100.0, 65.0, 18.0, 68.0, 52.0, 46.0, 43.0, 37.0, 12.0, 34.0, 24.0, 55.0, 22.0, 18.0, 107.0, 23.0, 30.0, 30.0, 25.0, 19.0, 169.68914190250104, 124.00068721717476, 117.44253542741943, 19.838054305073317, 23.26687591834053, 58.898935452799826, 12.570067375765205, 91.22375772541606, 8.033626916573235, 7.07868305808873, 6.210563507912061, 28.28217433050233, 52.836575647108106, 5.289311057171188, 5.246598969643413, 4.389660050095006, 4.38932504795033, 55.63129588617556, 4.367648791520136, 8.65884862394584, 32.402864586488235, 5.2618167220924645, 4.332540395028209, 5.152739203293385, 8.752263187109147, 3.4785335185991926, 3.4784866520527737, 3.477695545241445, 3.47887094025102, 3.4775828132714652, 4.294648341777276, 107.22051046015002, 8.69465521481206, 8.335990036050692, 16.033717503696845, 63.85431950949434, 62.814308507415035, 20.50082619943732, 65.05068822481311, 61.48603433163452, 18.955566031842558, 122.8610037044305, 22.865353728501624, 26.16763063727611, 100.76783910299632, 18.31422699392843, 34.13796326264608, 46.1962140609536, 22.75077285428169, 31.92163282199393, 33.42045440122025, 68.75703295888277, 38.45382114584816, 47.70570323778175, 100.64793512116076, 14.121178094985813, 8.771475473068552, 6.08689410740614, 12.924658825053777, 14.140641107033996, 6.085426155725789, 5.203872578392327, 4.312980270224018, 4.312772548958702, 4.312455520261636, 4.310935517006608, 222.06528171148003, 24.37651444012403, 14.90036819458638, 6.772288906992124, 3.420133328669808, 3.4204305703799402, 3.4193237566545065, 3.420601211608224, 3.419677517971574, 3.4206165754628364, 3.4196690922654924, 3.420310242501776, 3.4190134736643443, 3.418762112718316, 30.701845722155714, 3.420338585864527, 6.611590182512077, 8.205508961229645, 10.307581013171637, 15.364027113187696, 11.112066239455412, 9.409518366787347, 19.72268521896558, 5.826206998789919, 20.32047316376631, 13.262316048967365, 7.389458414200564, 18.48054236705326, 26.626019818772463, 68.75703295888277, 37.309909548203095, 47.70570323778175, 22.27856894071043, 43.82599835369867, 21.914162739060846, 122.8610037044305, 25.594460981407998, 18.678067801054343, 100.76783910299632, 39.10684265544375, 22.423893861471875, 38.45382114584816, 65.05068822481311, 33.42045440122025, 34.53846966785928, 62.814308507415035, 61.48603433163452, 46.1962140609536, 107.22051046015002, 63.85431950949434, 30.557487513634527, 6.080941274066791, 6.080783724148362, 12.03757307452, 3.0323650054039755, 3.033637565620632, 2.2691746183096817, 2.2688836214923773, 2.2693240555768552, 2.2687702045418927, 2.2699150372183787, 2.2701706789978284, 2.2701384594028777, 2.2700634268950495, 2.270321700622724, 2.2717799579160753, 2.2733041727529844, 4.41806594230836, 2.2761379195141953, 3.613877764889836, 2.8175322784393413, 1.5068934396991047, 1.5070101054452445, 1.5070255084445447, 1.5070156958660323, 1.5069989273259687, 1.5068561422324729, 1.507009371107899, 1.5070474219341092, 1.5070168811053695, 1.5070238735563062, 2.8035071144387755, 5.597860371896613, 10.481258586237908, 2.8943175745215863, 4.501248924595583, 2.8929339041371325, 2.8949778105196864, 13.891503291756392, 15.611440446340726, 19.614958454307374, 7.506773585824929, 10.720228463935785, 100.76783910299632, 15.339280103557906, 21.20561135151992, 34.13796326264608, 34.53846966785928, 12.600522662567615, 38.45382114584816, 31.92163282199393, 43.82599835369867, 22.413349390135764, 13.452060970611925, 22.101391719666566, 7.695298642552978, 24.738345585666117, 21.914162739060846, 68.75703295888277, 122.8610037044305, 61.48603433163452, 222.06528171148003, 107.22051046015002, 46.1962140609536, 39.10684265544375, 63.85431950949434, 62.814308507415035, 33.42045440122025, 37.309909548203095, 3.2403975370877665, 1.9911266922633037, 1.9911385600208826, 1.9923160022262194, 1.992807720598548, 1.9931037895615367, 1.9933192765370433, 3.1520991552767574, 3.506333620399531, 1.3678718266461942, 1.3676951532928001, 1.367933291240149, 1.3675435785509176, 1.3675197774633794, 1.3678937768355477, 1.3676955466376701, 1.3678146172015269, 1.3676717722399347, 1.3674636077163904, 1.3675396244701525, 1.367793887958033, 1.3675645057929917, 1.3679663923902987, 1.367607103696152, 1.3676984188083186, 1.3676445458358053, 1.3678718231392564, 1.3678857079278515, 1.367914360242323, 1.3679181412054697, 4.893570820354885, 5.964176168307665, 2.8838455223106867, 2.8889795358045216, 18.955566031842558, 5.298321483343516, 6.07384154924127, 18.678067801054343, 46.1962140609536, 65.05068822481311, 3.775653969385751, 3.7944045212349935, 30.557487513634527, 68.75703295888277, 37.309909548203095, 4.185798734088727, 9.778199327924215, 4.666221612704965, 4.543026323433245, 122.8610037044305, 25.594460981407998, 18.48054236705326, 222.06528171148003, 63.85431950949434, 22.27856894071043, 39.10684265544375, 15.176762228996097, 47.70570323778175, 61.48603433163452, 62.814308507415035, 22.101391719666566, 19.614958454307374, 21.565903362003997, 24.17563049004358, 1.81821255088416, 1.279833136301062, 1.2798831885721325, 1.2799370471296325, 1.2799471533395312, 1.2799510568170471, 1.2799616668773428, 1.27999088675223, 1.2795582409788744, 1.27959710300467, 1.279586958415849, 1.2800813290254234, 1.2796298680121103, 1.279603547330049, 1.279683582381494, 1.279721236078498, 1.2796447056663802, 1.2797483297323984, 1.2798171168077892, 1.2804387262578016, 1.2804396774378202, 1.2805116664680058, 1.280478617979832, 1.2805328998834669, 1.2805614956199585, 1.2805778468474396, 1.2806403751704067, 1.2806735071441568, 1.2804772010957262, 1.2814672912180654, 20.917786956431286, 4.904685241962591, 26.16763063727611, 6.634738002039698, 24.17563049004358, 22.413349390135764, 122.8610037044305, 4.4309826495190086, 10.397032507715057, 10.705415686956801, 34.13796326264608, 5.14209329140945, 222.06528171148003, 43.82599835369867, 5.964176168307665, 21.565903362003997, 6.334739676507973, 39.10684265544375, 61.48603433163452, 47.70570323778175, 6.949009596504197, 12.298989441998057, 22.101391719666566, 7.756480439686771, 6.351876737468661, 65.05068822481311, 25.594460981407998, 5.29052469676866, 8.860086653096173, 107.22051046015002, 100.76783910299632, 22.865353728501624, 62.814308507415035, 22.75077285428169, 68.75703295888277, 63.85431950949434, 91.22375772541606, 24.738345585666117, 15.364027113187696], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.6442, -2.965, -3.0225, -4.8116, -4.6608, -3.7341, -5.2844, -3.3139, -5.757, -5.9025, -6.0362, -4.523, -3.9112, -6.2177, -6.2394, -6.4253, -6.4256, -3.8926, -6.439, -5.7565, -4.4391, -6.2621, -6.4611, -6.2896, -5.7705, -6.6959, -6.6962, -6.6967, -6.6965, -6.6972, -6.4864, -3.4413, -5.8424, -5.9191, -5.3629, -4.1613, -4.2061, -5.1821, -4.2949, -4.3572, -5.2798, -3.8761, -5.1597, -5.0666, -4.1276, -5.3488, -4.9908, -4.933, -5.3523, -5.2299, -5.2954, -5.227, -5.3247, -5.337, -3.0112, -5.0109, -5.5123, -5.911, -5.1605, -5.0788, -5.9223, -6.0836, -6.2956, -6.2957, -6.2962, -6.2984, -2.3567, -4.5682, -5.083, -5.8758, -6.5677, -6.5676, -6.5681, -6.5683, -6.569, -6.5691, -6.5694, -6.5693, -6.5723, -6.5766, -4.3859, -6.5848, -5.9339, -5.7271, -5.5123, -5.1314, -5.4693, -5.6328, -4.9649, -6.0835, -4.9717, -5.3557, -5.8786, -5.0838, -4.7875, -3.9779, -4.503, -4.3195, -4.9578, -4.4287, -5.0366, -3.7358, -4.9305, -5.1618, -4.0969, -4.7182, -5.0993, -4.7685, -4.5994, -4.9332, -4.9722, -4.7459, -4.7653, -4.8947, -4.8055, -4.9062, -5.057, -5.0882, -5.0889, -4.41, -5.9007, -5.9014, -6.2739, -6.2743, -6.2743, -6.2749, -6.2751, -6.275, -6.2755, -6.2761, -6.2764, -6.2789, -6.287, -5.6288, -6.2958, -5.8377, -6.2503, -6.8781, -6.8781, -6.8781, -6.8781, -6.8781, -6.8782, -6.8782, -6.8781, -6.8782, -6.8782, -6.2743, -5.6295, -5.0888, -6.2731, -5.8678, -6.2745, -6.2762, -4.8426, -4.7409, -4.5453, -5.4271, -5.2475, -3.519, -5.0154, -4.8772, -4.5946, -4.5962, -5.2474, -4.578, -4.7051, -4.5279, -4.9482, -5.2461, -4.9676, -5.5901, -4.9851, -5.0839, -4.4948, -4.2628, -4.5942, -4.0025, -4.3595, -4.7614, -4.9317, -4.9172, -4.9614, -5.0787, -5.0781, -5.1423, -5.7867, -5.7874, -5.7876, -5.7876, -5.7883, -5.7887, -5.4131, -5.412, -6.3915, -6.3919, -6.3922, -6.3925, -6.3925, -6.3923, -6.3924, -6.3924, -6.3925, -6.3926, -6.3926, -6.3924, -6.3926, -6.3923, -6.3926, -6.3926, -6.3926, -6.3924, -6.3924, -6.3924, -6.3925, -5.1422, -5.1415, -5.7884, -5.7995, -4.356, -5.4212, -5.4155, -4.7671, -4.2685, -4.094, -5.7881, -5.7857, -4.6072, -4.1726, -4.6111, -5.7976, -5.4136, -5.7857, -5.8008, -4.2046, -4.9746, -5.1581, -4.054, -4.6465, -5.1382, -4.9611, -5.4103, -5.1702, -5.164, -5.2305, -5.4027, -5.4233, -5.4399, -5.424, -5.6254, -6.2269, -6.227, -6.2271, -6.2271, -6.2272, -6.2272, -6.2272, -6.2276, -6.2278, -6.2278, -6.2275, -6.2278, -6.2281, -6.2281, -6.2284, -6.2285, -6.2284, -6.2288, -6.2285, -6.2285, -6.2287, -6.2288, -6.2289, -6.2289, -6.229, -6.2292, -6.2293, -6.2312, -6.2309, -3.7763, -5.2581, -4.2045, -5.2821, -4.5943, -4.7142, -3.9041, -5.6264, -5.2458, -5.2464, -4.7469, -5.6212, -4.0184, -4.7925, -5.6174, -5.1634, -5.626, -4.981, -4.8619, -4.9526, -5.631, -5.4412, -5.243, -5.6211, -5.6954, -4.9307, -5.2471, -5.7677, -5.6262, -4.8927, -4.9247, -5.4825, -5.3823, -5.5249, -5.4468, -5.4721, -5.4786, -5.6078, -5.6151], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9279, 0.9207, 0.9176, 0.9068, 0.8982, 0.8961, 0.8903, 0.8788, 0.8654, 0.8464, 0.8435, 0.8408, 0.8276, 0.8226, 0.8091, 0.8015, 0.8012, 0.7946, 0.7927, 0.7909, 0.7886, 0.7834, 0.7788, 0.7768, 0.7661, 0.7635, 0.7632, 0.763, 0.7628, 0.7624, 0.7622, 0.5898, 0.7009, 0.6664, 0.5684, 0.3881, 0.3597, 0.5034, 0.2359, 0.23, 0.4841, 0.0188, 0.4166, 0.3748, -0.0344, 0.4495, 0.1848, -0.0599, 0.2291, 0.0129, -0.0986, -0.7516, -0.2682, -0.496, 1.0832, 1.0474, 1.0222, 0.9888, 0.9864, 0.9781, 0.9778, 0.973, 0.9488, 0.9487, 0.9483, 0.9464, 0.9463, 0.9442, 0.9216, 0.9173, 0.9086, 0.9086, 0.9085, 0.9079, 0.9074, 0.907, 0.907, 0.907, 0.9044, 0.9001, 0.8958, 0.8915, 0.8833, 0.8741, 0.8608, 0.8426, 0.8287, 0.8315, 0.7593, 0.8602, 0.7227, 0.7654, 0.8273, 0.7055, 0.6367, 0.4975, 0.5838, 0.5215, 0.6446, 0.4971, 0.5823, 0.1591, 0.5331, 0.6168, -0.0037, 0.3215, 0.4966, 0.288, -0.0686, 0.2636, 0.1917, -0.1801, -0.1781, -0.0216, -0.7744, -0.3568, 0.2294, 1.8126, 1.812, 1.8079, 1.6959, 1.6948, 1.6127, 1.6124, 1.6122, 1.6118, 1.6112, 1.6111, 1.6107, 1.6101, 1.6097, 1.6065, 1.5978, 1.5915, 1.5877, 1.5835, 1.4198, 1.4179, 1.4178, 1.4178, 1.4177, 1.4177, 1.4177, 1.4177, 1.4177, 1.4177, 1.4177, 1.4008, 1.3541, 1.2676, 1.3701, 1.3339, 1.3692, 1.3668, 1.2321, 1.2171, 1.1844, 1.2631, 1.0864, 0.5742, 0.9601, 0.7746, 0.581, 0.5677, 0.9249, 0.4785, 0.5376, 0.3978, 0.6481, 0.8608, 0.6427, 1.0753, 0.5125, 0.5349, -0.0193, -0.3679, -0.007, -0.6995, -0.3284, 0.1116, 0.108, -0.3678, -0.3956, 0.1182, 0.0086, 2.388, 2.2306, 2.2299, 2.2291, 2.2289, 2.228, 2.2274, 2.1448, 2.0394, 2.0012, 2.001, 2.0005, 2.0005, 2.0005, 2.0004, 2.0004, 2.0004, 2.0004, 2.0004, 2.0004, 2.0004, 2.0003, 2.0003, 2.0003, 2.0003, 2.0003, 2.0003, 2.0003, 2.0003, 2.0002, 1.9759, 1.7787, 1.8585, 1.8456, 1.4079, 1.6175, 1.4865, 1.0116, 0.6046, 0.4369, 1.5893, 1.5867, 0.6792, 0.3028, 0.4757, 1.4767, 1.0123, 1.38, 1.3916, -0.3096, 0.489, 0.6312, -0.751, -0.0971, 0.4642, 0.0786, 0.5759, -0.3292, -0.5768, -0.6647, 0.2076, 0.3064, 0.195, 0.0967, 2.4827, 2.2324, 2.2322, 2.2321, 2.232, 2.232, 2.232, 2.2319, 2.2319, 2.2316, 2.2316, 2.2316, 2.2316, 2.2314, 2.2313, 2.231, 2.231, 2.2309, 2.2304, 2.2303, 2.2303, 2.23, 2.23, 2.2298, 2.2298, 2.2296, 2.2294, 2.2293, 2.2276, 2.2271, 1.8891, 1.8578, 1.237, 1.5316, 0.9263, 0.8822, -0.0091, 1.591, 1.1187, 1.0889, 0.4287, 1.4473, -0.7153, 0.1333, 1.3028, 0.4715, 1.234, 0.0587, -0.2747, -0.1116, 1.1364, 0.7553, 0.3674, 1.0363, 1.1618, -0.3999, 0.2165, 1.2724, 0.8982, -0.8616, -0.8315, 0.0938, -0.8165, 0.0564, -0.9714, -0.9227, -1.2859, -0.1102, 0.3589]}, \"token.table\": {\"Topic\": [2, 4, 1, 2, 3, 5, 2, 3, 5, 3, 4, 2, 3, 4, 5, 2, 3, 4, 3, 5, 1, 2, 3, 2, 2, 3, 4, 4, 1, 4, 5, 1, 2, 5, 5, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 4, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 2, 3, 4, 5, 5, 4, 2, 4, 2, 5, 1, 3, 5, 1, 3, 5, 4, 1, 5, 5, 1, 2, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 3, 5, 2, 2, 4, 3, 1, 2, 3, 4, 5, 1, 2, 4, 2, 5, 3, 4, 5, 4, 5, 1, 2, 3, 5, 3, 5, 4, 3, 3, 1, 3, 1, 3, 4, 2, 1, 1, 2, 4, 1, 2, 3, 4, 1, 5, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 4, 4, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 2, 4, 2, 1, 2, 3, 4, 5, 1, 2, 5, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 5, 5, 2, 1, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 3, 4, 2, 4, 5, 1, 2, 3, 5, 1, 3, 5, 3, 4, 3, 1, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 4, 3, 1, 2, 3, 4, 5, 5, 1, 2, 4, 5, 1, 4, 1, 2, 3, 4, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 5, 3, 1, 5, 1, 1, 3, 5, 4, 3, 3, 4, 5, 5, 1, 2, 3, 1, 3, 2, 3, 2, 4, 5, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 4, 2, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 3, 4, 4, 4, 4, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 5, 2, 3, 4, 4, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 2, 5, 2, 1, 2, 4, 1, 2, 3, 5, 2, 2, 3, 4, 5, 4, 2, 2, 4, 2, 3, 4, 5, 4, 2, 1, 2, 4, 5, 3, 4, 3, 1, 2, 3, 4, 4, 2, 4, 1, 2, 3, 1, 3, 5, 1, 1, 2, 3, 4, 5, 1, 3, 2, 4, 2, 4, 1, 2, 3, 4, 5, 3, 2, 3, 5, 2, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 2, 3, 4, 5, 5, 3, 3, 1, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 3, 1, 2, 3, 4, 3, 4, 1, 2, 3, 1, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 5], \"Freq\": [0.34675921170657853, 0.34675921170657853, 0.15072185212024544, 0.3014437042404909, 0.3014437042404909, 0.3014437042404909, 0.4513671476951289, 0.22568357384756446, 0.22568357384756446, 0.8810902466423851, 0.7312041574640541, 0.2664260453754204, 0.5328520907508408, 0.1332130226877102, 0.1332130226877102, 0.2043497553648318, 0.2043497553648318, 0.6130492660944954, 0.8797766809964496, 0.781466914661477, 0.8895353157235208, 0.0189262833132664, 0.0757051332530656, 0.8216351446965617, 0.8214369942654863, 0.6910091752217579, 0.34550458761087893, 0.7311841392156998, 0.808421570119804, 0.11548879573140057, 0.7808974694211887, 0.9507811910263987, 0.03395647110808567, 0.7809248790804232, 0.7814959862380607, 0.8050923040714627, 0.11501318629592323, 0.15210910515953288, 0.7098424907444867, 0.05070303505317762, 0.05070303505317762, 0.4879156759108958, 0.27648554968284095, 0.14637470277326872, 0.048791567591089574, 0.048791567591089574, 0.8626681695547636, 0.7310121107965691, 0.8099303771285904, 0.1799845282507979, 0.7809074405410494, 0.3988246760369988, 0.39068539693420284, 0.09767134923355071, 0.05697495371957125, 0.05697495371957125, 0.16464044902931615, 0.3292808980586323, 0.16464044902931615, 0.3292808980586323, 0.7809588481109098, 0.9660959093898951, 0.6595512072048719, 0.7812733973820083, 0.23890302987004605, 0.23890302987004605, 0.23890302987004605, 0.23890302987004605, 0.7813518587979149, 0.7311570839396819, 0.5297095592489832, 0.2648547796244916, 0.9914186979180695, 0.7809579839588937, 0.9838655150864547, 0.008064471435134874, 0.008064471435134874, 0.9841525399188703, 0.005893128981550122, 0.005893128981550122, 0.7311553382296839, 0.9313917419242432, 0.780937828359087, 0.5499907035146799, 0.2262048339764597, 0.7540161132548657, 0.19122481782281364, 0.28683722673422046, 0.09561240891140682, 0.04780620445570341, 0.33464343118992385, 0.9113018416961095, 0.7812884252726218, 0.6341207848665537, 0.14633556573843545, 0.14633556573843545, 0.048778521912811824, 0.7133921614464578, 0.3566960807232289, 0.9120472404628791, 0.8859633843744077, 0.14766056406240127, 0.6636169311346124, 0.4136396775305765, 0.20681983876528826, 0.1654558710122306, 0.0827279355061153, 0.12409190325917295, 0.09701597287687003, 0.7761277830149602, 0.09701597287687003, 0.877158786428595, 0.78150218195254, 0.6790301546365227, 0.2263433848788409, 0.7808593414579298, 0.7312508502472308, 0.7814431737406506, 0.28781079839149015, 0.28781079839149015, 0.28781079839149015, 0.14390539919574508, 0.7098410248232612, 0.3549205124116306, 0.7310932252251733, 0.659274536505429, 0.8809324244451446, 0.862348748063512, 0.8814907829800821, 0.6330594391030987, 0.05275495325859156, 0.31652971955154935, 0.8774460887937758, 0.9529983192787892, 0.760193714692769, 0.8581912728192598, 0.17163825456385196, 0.18778623444405274, 0.6384731971097792, 0.1502289875552422, 0.03755724688881055, 0.9577552167069633, 0.7812003638560525, 0.8815348491425722, 0.7310297997743839, 0.7815197213961831, 0.24253845024610368, 0.4446538254511901, 0.24253845024610368, 0.040423075041017276, 0.040423075041017276, 0.7310378961117922, 0.3058889986423816, 0.10196299954746053, 0.4588334979635724, 0.10196299954746053, 0.05098149977373027, 0.17863968258665044, 0.17863968258665044, 0.5359190477599514, 0.7312381233654173, 0.10627536511642155, 0.7439275558149508, 0.10627536511642155, 0.8626402055536232, 0.2945268322856801, 0.42542764663487126, 0.13090081434919115, 0.13090081434919115, 0.4919240806401466, 0.3074525504000916, 0.04611788256001374, 0.10760839264003207, 0.030745255040009162, 0.7312808870065362, 0.5017300178933433, 0.07071815149191282, 0.9193359693948667, 0.46868642622002216, 0.17575740983250832, 0.2636361147487625, 0.029292901638751385, 0.08787870491625416, 0.47157329417353705, 0.18862931766941482, 0.33010130592147596, 0.600625950723814, 0.2730117957835518, 0.05460235915671036, 0.05460235915671036, 0.2305803971733147, 0.5659700657890452, 0.10480927144241577, 0.06288556286544945, 0.041923708576966305, 0.699493032425683, 0.15855175401648813, 0.1025923114224335, 0.009326573765675772, 0.018653147531351544, 0.8773664658579227, 0.8628236900720491, 0.08987746771583845, 0.01797549354316769, 0.01797549354316769, 0.3461429849559389, 0.3461429849559389, 0.960822911145278, 0.9427368718887946, 0.02192411329973941, 0.010962056649869704, 0.010962056649869704, 0.010962056649869704, 0.09618129011888304, 0.6732690308321813, 0.1923625802377661, 0.6344978065337535, 0.31724890326687677, 0.5019284083863188, 0.5571978874187298, 0.2865589135296324, 0.09551963784321081, 0.03183987928107027, 0.015919939640535136, 0.032571331673338415, 0.8142832918334605, 0.06514266334667683, 0.06514266334667683, 0.032571331673338415, 0.9275457987233502, 0.12994947258710182, 0.25989894517420364, 0.3898484177613054, 0.12994947258710182, 0.12994947258710182, 0.7814201810578223, 0.7814920504765288, 0.927477615522706, 0.9158245525066182, 0.5794439637634626, 0.2349097150392416, 0.09396388601569663, 0.06264259067713109, 0.01566064766928277, 0.5662170575023024, 0.3774780383348683, 0.13465855944265756, 0.628406610732402, 0.08977237296177172, 0.13465855944265756, 0.04488618648088586, 0.8786813764022119, 0.5016757785723527, 0.8530854128701125, 0.12186934469573037, 0.12186934469573037, 0.2439224794970333, 0.4878449589940666, 0.08130749316567777, 0.08130749316567777, 0.8476152909747624, 0.8301332239695857, 0.27671107465652856, 0.6635587748160521, 0.9258123318709166, 0.880991027900556, 0.8713374510283917, 0.7803554619404105, 0.23013875293630187, 0.46027750587260374, 0.1534258352908679, 0.07671291764543395, 0.05114194509695597, 0.18901716886621447, 0.18901716886621447, 0.18901716886621447, 0.18901716886621447, 0.5018045592976957, 0.8810035316198584, 0.612280053317042, 0.26240573713587517, 0.08746857904529172, 0.04373428952264586, 0.04373428952264586, 0.7812798736904651, 0.6860542477104117, 0.18710570392102138, 0.062368567973673794, 0.062368567973673794, 0.7197705340399609, 0.11996175567332683, 0.11721286110222136, 0.5860643055111068, 0.11721286110222136, 0.11721286110222136, 0.07814190740148091, 0.9935623605155857, 0.7814036375488803, 0.18907156752639542, 0.5526707358463866, 0.14543966732799649, 0.10180776712959753, 0.014543966732799648, 0.9193069703965085, 0.03535796039986572, 0.03535796039986572, 0.03535796039986572, 0.47357905031604247, 0.31571936687736163, 0.15785968343868081, 0.3121670144910563, 0.5351434534132394, 0.13378586335330986, 0.04459528778443662, 0.22308133929329307, 0.3123138750106103, 0.2676976071519517, 0.04461626785865862, 0.13384880357597584, 0.8624323968590366, 0.9278728443559479, 0.8803669532478041, 0.48350005823779313, 0.3516364059911223, 0.043954550748890285, 0.043954550748890285, 0.043954550748890285, 0.37169025704858616, 0.29735220563886894, 0.37169025704858616, 0.781255562324618, 0.6635625735436474, 0.776286134847149, 0.7812822563735413, 0.9546488209868881, 0.9792022931169692, 0.00851480254884321, 0.00851480254884321, 0.7312269335479302, 0.8813197018226673, 0.9138054599463877, 0.08307322363148979, 0.7813213025445106, 0.7809817343375486, 0.18656318815669415, 0.3731263763133883, 0.46640797039173537, 0.9232458639255124, 0.8222411259459701, 0.9274329464512571, 0.6635630954230592, 0.7810452241196459, 0.13017420401994098, 0.06508710200997049, 0.10707745690306915, 0.6424647414184149, 0.053538728451534574, 0.2141549138061383, 0.2257314265996593, 0.5643285664991483, 0.11286571329982965, 0.11286571329982965, 0.2635459646971226, 0.2635459646971226, 0.2635459646971226, 0.8772757034059424, 0.40724733827033527, 0.3132671832848733, 0.25061374662789865, 0.03132671832848733, 0.03132671832848733, 0.3202779408591976, 0.12811117634367902, 0.5124447053747161, 0.14397289897248602, 0.28794579794497205, 0.5039051464037011, 0.7312402376548656, 0.6635658803268331, 0.73110430511785, 0.7310552293984086, 0.7310399167261116, 0.5022282127428592, 0.159722545131918, 0.5476201547380045, 0.22817506447416858, 0.06845251934225056, 0.23184746384467608, 0.46369492768935217, 0.13910847830680564, 0.09273898553787042, 0.09273898553787042, 0.5156978130871857, 0.1289244532717964, 0.1289244532717964, 0.1289244532717964, 0.1289244532717964, 0.6635655569838074, 0.7311695834463469, 0.7813616389928204, 0.4402351775255761, 0.22011758876278806, 0.22011758876278806, 0.7310509170627092, 0.8813777414317321, 0.0912651796837807, 0.5932236679445746, 0.22816294920945177, 0.04563258984189035, 0.7808391400474537, 0.1340126540253381, 0.5896556777114876, 0.16081518483040572, 0.10721012322027049, 0.7814759759816235, 0.6429184571585163, 0.2143061523861721, 0.2860573974762886, 0.4420887051906279, 0.2340469615715089, 0.7562477198337553, 0.15124954396675105, 0.8772778649212909, 0.6136099090213293, 0.10226831817022154, 0.20453663634044308, 0.19447332892046762, 0.19447332892046762, 0.38894665784093524, 0.19447332892046762, 0.8770348660296942, 0.16766775021062968, 0.16766775021062968, 0.503003250631889, 0.16766775021062968, 0.7311568736612404, 0.8775106021093257, 0.9284577769077065, 0.07737148140897554, 0.8646106159424661, 0.07205088466187218, 0.03602544233093609, 0.027019081748202067, 0.7310626482101339, 0.8771134158302724, 0.5732272901556597, 0.22929091606226384, 0.03821515267704397, 0.19107576338521987, 0.6913396801564793, 0.34566984007823964, 0.881032651468934, 0.3590615452422411, 0.4488269315528014, 0.17953077262112055, 0.029921795436853426, 0.731062650084426, 0.811967489859555, 0.1353279149765925, 0.0671124355412453, 0.8724616620361889, 0.0671124355412453, 0.22216056404608764, 0.6664816921382629, 0.22216056404608764, 0.8624440166328071, 0.3736426605903305, 0.2802319954427479, 0.09341066514758263, 0.09341066514758263, 0.18682133029516526, 0.7997931335417353, 0.11425616193453361, 0.877082559716089, 0.502225219318495, 0.28519818940847236, 0.5703963788169447, 0.36196815573751084, 0.18098407786875542, 0.2714761168031331, 0.09049203893437771, 0.09049203893437771, 0.6635491262223344, 0.4077733639029011, 0.20388668195145054, 0.4077733639029011, 0.8771061474435046, 0.3771044446151081, 0.3374092399187809, 0.2580188305261266, 0.019847602348163584, 0.19767062003965005, 0.3953412400793001, 0.19767062003965005, 0.1317804133597667, 0.06589020667988335, 0.05411096601703529, 0.7034425582214588, 0.05411096601703529, 0.1623328980511059, 0.05411096601703529, 0.8770388052892975, 0.5555325114246973, 0.07936178734638533, 0.3968089367319266, 0.28622516802887177, 0.4770419467147862, 0.09540838934295724, 0.09540838934295724, 0.780982314493557, 0.663570478961394, 0.8222624297824817, 0.9112322946086515, 0.19557632299211733, 0.39115264598423466, 0.39115264598423466, 0.06519210766403911, 0.06519210766403911, 0.6636333568766933, 0.041023092224948626, 0.8614849367239211, 0.041023092224948626, 0.041023092224948626, 0.6635594946748782, 0.3679955239961731, 0.3247019329377998, 0.17317436423349322, 0.12988077317511992, 0.690851581912807, 0.3454257909564035, 0.864121131181587, 0.0925844069123129, 0.030861468970770963, 0.9453026955601441, 0.14763435751827558, 0.6889603350852861, 0.09842290501218373, 0.049211452506091866, 0.049211452506091866, 0.9455502353308253, 0.2895322258387659, 0.40534511617427227, 0.2605790032548893, 0.02895322258387659, 0.02895322258387659, 0.1574337855300571, 0.6297351421202284, 0.1574337855300571], \"Term\": [\"able\", \"able\", \"actually\", \"actually\", \"actually\", \"actually\", \"add\", \"add\", \"add\", \"advice\", \"afte\", \"ago\", \"ago\", \"ago\", \"ago\", \"agree\", \"agree\", \"agree\", \"allergic\", \"allone\", \"amazing\", \"amazing\", \"amazing\", \"analogy\", \"andreas\", \"appreciate\", \"appreciate\", \"arm\", \"ass\", \"ass\", \"await\", \"awesome\", \"awesome\", \"ball\", \"barely\", \"beat\", \"beat\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"body\", \"body\", \"body\", \"body\", \"body\", \"bowel\", \"brah\", \"break\", \"break\", \"burkitt\", \"cancer\", \"cancer\", \"cancer\", \"cancer\", \"cancer\", \"care\", \"care\", \"care\", \"care\", \"cat\", \"celebrate\", \"chem\", \"chest\", \"child\", \"child\", \"child\", \"child\", \"clickbaite\", \"college\", \"completely\", \"completely\", \"condolence\", \"cong\", \"congrat\", \"congrat\", \"congrat\", \"congratulation\", \"congratulation\", \"congratulation\", \"conten\", \"continue\", \"courageous\", \"crc\", \"cry\", \"cry\", \"dad\", \"dad\", \"dad\", \"dad\", \"dad\", \"dance\", \"dark\", \"day\", \"day\", \"day\", \"day\", \"dear\", \"dear\", \"deep\", \"deeply\", \"deeply\", \"depressing\", \"diagnose\", \"diagnose\", \"diagnose\", \"diagnose\", \"diagnose\", \"die\", \"die\", \"die\", \"disease\", \"dm\", \"doctor\", \"doctor\", \"doin\", \"doubl\", \"drug\", \"dude\", \"dude\", \"dude\", \"dude\", \"early\", \"early\", \"embrace\", \"emotion\", \"emotional\", \"encourage\", \"energy\", \"enjoy\", \"enjoy\", \"enjoy\", \"ewe\", \"excellent\", \"face\", \"fair\", \"fair\", \"family\", \"family\", \"family\", \"family\", \"fantastic\", \"fast\", \"favorite\", \"feb\", \"fee\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"fellow\", \"fight\", \"fight\", \"fight\", \"fight\", \"fight\", \"fighting\", \"fighting\", \"fighting\", \"find\", \"forget\", \"forget\", \"forget\", \"freak\", \"friend\", \"friend\", \"friend\", \"friend\", \"fuck\", \"fuck\", \"fuck\", \"fuck\", \"fuck\", \"fuckcancer\", \"funny\", \"gene\", \"gene\", \"get\", \"get\", \"get\", \"get\", \"get\", \"give\", \"give\", \"give\", \"glad\", \"glad\", \"glad\", \"glad\", \"go\", \"go\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gorgeous\", \"great\", \"great\", \"great\", \"great\", \"hand\", \"hand\", \"happen\", \"happy\", \"happy\", \"happy\", \"happy\", \"happy\", \"hard\", \"hard\", \"hard\", \"health\", \"health\", \"healthcare\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"heart\", \"heart\", \"heart\", \"heart\", \"heart\", \"heartbreake\", \"help\", \"help\", \"help\", \"help\", \"help\", \"hi\", \"hoff\", \"home\", \"hoo\", \"hope\", \"hope\", \"hope\", \"hope\", \"hope\", \"hospice\", \"hospice\", \"hug\", \"hug\", \"hug\", \"hug\", \"hug\", \"humble\", \"humour\", \"hurt\", \"hurt\", \"hurt\", \"imagine\", \"imagine\", \"imagine\", \"imagine\", \"incredible\", \"incurable\", \"incurable\", \"inevitability\", \"insurance\", \"keep\", \"kick\", \"king\", \"know\", \"know\", \"know\", \"know\", \"know\", \"late\", \"late\", \"late\", \"late\", \"laugh\", \"learn\", \"life\", \"life\", \"life\", \"life\", \"life\", \"light\", \"live\", \"live\", \"live\", \"live\", \"long\", \"long\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"loss\", \"lost\", \"love\", \"love\", \"love\", \"love\", \"love\", \"luck\", \"luck\", \"luck\", \"luck\", \"lung\", \"lung\", \"lung\", \"m\", \"m\", \"m\", \"m\", \"man\", \"man\", \"man\", \"man\", \"man\", \"mate\", \"memory\", \"mix\", \"mom\", \"mom\", \"mom\", \"mom\", \"mom\", \"month\", \"month\", \"month\", \"mov\", \"nbiggest\", \"ncongrat\", \"ncongratula\", \"ned\", \"news\", \"news\", \"news\", \"nlook\", \"number\", \"nurse\", \"nurse\", \"nyike\", \"occur\", \"old\", \"old\", \"old\", \"omg\", \"oncology\", \"pain\", \"panpsychism\", \"pass\", \"pass\", \"pass\", \"peace\", \"peace\", \"peace\", \"peace\", \"people\", \"people\", \"people\", \"people\", \"personally\", \"personally\", \"personally\", \"picture\", \"post\", \"post\", \"post\", \"post\", \"post\", \"pray\", \"pray\", \"pray\", \"prayer\", \"prayer\", \"prayer\", \"professor\", \"profile\", \"pudd\", \"pudde\", \"puddi\", \"pudding\", \"read\", \"read\", \"read\", \"read\", \"really\", \"really\", \"really\", \"really\", \"really\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"regard\", \"rem\", \"remarkable\", \"rest\", \"rest\", \"rest\", \"ryan\", \"saint\", \"say\", \"say\", \"say\", \"say\", \"scary\", \"send\", \"send\", \"send\", \"send\", \"sentence\", \"seriously\", \"seriously\", \"share\", \"share\", \"share\", \"sharing\", \"sharing\", \"shed\", \"shit\", \"shit\", \"shit\", \"similar\", \"similar\", \"similar\", \"similar\", \"single\", \"situation\", \"situation\", \"situation\", \"situation\", \"someday\", \"son\", \"song\", \"song\", \"sorry\", \"sorry\", \"sorry\", \"sorry\", \"soul\", \"speechless\", \"stage\", \"stage\", \"stage\", \"stage\", \"state\", \"state\", \"stay_strong\", \"story\", \"story\", \"story\", \"story\", \"strange\", \"strength\", \"strength\", \"strong\", \"strong\", \"strong\", \"sub\", \"sub\", \"sub\", \"super\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"survivor\", \"survivor\", \"sympathy\", \"tak\", \"tea\", \"tea\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"termin\", \"terminal\", \"terminal\", \"terminal\", \"terribly\", \"thank\", \"thank\", \"thank\", \"thank\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"think\", \"thro\", \"today\", \"today\", \"today\", \"try\", \"try\", \"try\", \"try\", \"ure\", \"user\", \"val\", \"victory\", \"want\", \"want\", \"want\", \"want\", \"want\", \"wha\", \"wife\", \"wife\", \"wife\", \"wife\", \"wisdom\", \"wish\", \"wish\", \"wish\", \"wish\", \"woman\", \"woman\", \"wonderful\", \"wonderful\", \"wonderful\", \"woo\", \"word\", \"word\", \"word\", \"word\", \"word\", \"yay\", \"year\", \"year\", \"year\", \"year\", \"year\", \"young\", \"young\", \"young\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 4, 2, 3, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2247224492579238564881133034\", ldavis_el2247224492579238564881133034_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2247224492579238564881133034\", ldavis_el2247224492579238564881133034_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2247224492579238564881133034\", ldavis_el2247224492579238564881133034_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ldavisualizer import ldavisualizer as lda\n",
    "\n",
    "lda(df.comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223673f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
